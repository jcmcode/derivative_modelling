{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ae41ae",
   "metadata": {},
   "source": "# Breeden-Litzenberger Model Implementation\n# Extracting Risk-Neutral Probability Distributions from Option Prices\n\nThis notebook implements the **Breeden-Litzenberger (1978)** method to recover the\nrisk-neutral probability density (RND) implied by market option prices on SPY (S&P 500 ETF).\n\n**Pipeline overview:**\n1. Fetch live option chain data for SPY via yfinance\n2. Clean and filter for liquid, near-term options (~30 days to expiry)\n3. Compute implied volatilities and construct the volatility smile\n4. Interpolate/extrapolate the smile using a clamped cubic spline (Malz 2014)\n5. Build a fine-grid call price function via Black-Scholes with the interpolated vols\n6. Apply Breeden-Litzenberger finite differencing to extract the RND\n7. Compare the market-implied distribution against the theoretical lognormal (Black-Scholes)\n8. Analyse tail risk, skewness, and kurtosis"
  },
  {
   "cell_type": "markdown",
   "id": "69347ade",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61266aab",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport yfinance as yf\nfrom scipy.interpolate import CubicSpline\nfrom scipy.stats import norm, lognorm\nfrom scipy.optimize import brentq\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Compatibility: numpy >= 2.0 renamed trapz -> trapezoid\ntrapz = np.trapezoid if hasattr(np, 'trapezoid') else np.trapz\n\nprint(\"All imports loaded successfully.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "FIGURES_DIR = os.path.join(os.path.dirname(os.getcwd()), 'figures')\n",
    "FIGURES_HTML_DIR = os.path.join(FIGURES_DIR, 'html')\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
    "os.makedirs(FIGURES_HTML_DIR, exist_ok=True)\n",
    "\n",
    "def save_plotly_figure(fig, name, width=1200, height=700):\n",
    "    \"\"\"Save a Plotly figure as PNG and interactive HTML.\"\"\"\n",
    "    png_path = os.path.join(FIGURES_DIR, f'{name}.png')\n",
    "    html_path = os.path.join(FIGURES_HTML_DIR, f'{name}.html')\n",
    "    fig.write_image(png_path, width=width, height=height, scale=2)\n",
    "    fig.write_html(html_path, include_plotlyjs='cdn')\n",
    "    print(f\"Saved: {png_path}\")\n",
    "\n",
    "print(f\"Figures directory: {FIGURES_DIR}\")\n",
    "print(f\"HTML directory: {FIGURES_HTML_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e149f4ee",
   "metadata": {},
   "source": "## Black-Scholes Pricing Functions\n\nCore pricing engine used throughout. The BS formula gives us:\n- A way to **invert** market prices into implied volatilities\n- A way to **reconstruct** call prices from interpolated vols on a fine strike grid\n- The **theoretical lognormal density** to compare against the market-implied RND"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b13a15d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": "def bs_d1(S, K, T, r, q, sigma):\n    \"\"\"Compute Black-Scholes d1 parameter.\"\"\"\n    return (np.log(S / K) + (r - q + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n\ndef bs_d2(S, K, T, r, q, sigma):\n    \"\"\"Compute Black-Scholes d2 parameter.\"\"\"\n    return bs_d1(S, K, T, r, q, sigma) - sigma * np.sqrt(T)\n\ndef bs_call_price(S, K, T, r, q, sigma):\n    \"\"\"\n    Black-Scholes European call price.\n    \n    Parameters:\n        S     : Current underlying price\n        K     : Strike price (scalar or array)\n        T     : Time to expiration (years)\n        r     : Risk-free rate (continuously compounded)\n        q     : Dividend yield (continuously compounded)\n        sigma : Volatility (scalar or array matching K)\n    \n    Returns:\n        Call option price(s)\n    \"\"\"\n    d1 = bs_d1(S, K, T, r, q, sigma)\n    d2 = d1 - sigma * np.sqrt(T)\n    return S * np.exp(-q * T) * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n\ndef bs_put_price(S, K, T, r, q, sigma):\n    \"\"\"Black-Scholes European put price via put-call parity.\"\"\"\n    return bs_call_price(S, K, T, r, q, sigma) - S * np.exp(-q * T) + K * np.exp(-r * T)\n\ndef bs_vega(S, K, T, r, q, sigma):\n    \"\"\"Black-Scholes vega (sensitivity of price to volatility).\"\"\"\n    d1 = bs_d1(S, K, T, r, q, sigma)\n    return S * np.exp(-q * T) * norm.pdf(d1) * np.sqrt(T)\n\ndef bs_delta_call(S, K, T, r, q, sigma):\n    \"\"\"Black-Scholes call delta: dC/dS = e^{-qT} * N(d1).\"\"\"\n    d1 = bs_d1(S, K, T, r, q, sigma)\n    return np.exp(-q * T) * norm.cdf(d1)\n\ndef bs_gamma(S, K, T, r, q, sigma):\n    \"\"\"Black-Scholes gamma: d\u00b2C/dS\u00b2 = e^{-qT} * n(d1) / (S * sigma * sqrt(T)).\"\"\"\n    d1 = bs_d1(S, K, T, r, q, sigma)\n    return np.exp(-q * T) * norm.pdf(d1) / (S * sigma * np.sqrt(T))\n\ndef bs_theta_call(S, K, T, r, q, sigma):\n    \"\"\"Black-Scholes call theta (per calendar day): dC/dt / 365.\"\"\"\n    d1 = bs_d1(S, K, T, r, q, sigma)\n    d2 = d1 - sigma * np.sqrt(T)\n    term1 = -S * np.exp(-q * T) * norm.pdf(d1) * sigma / (2 * np.sqrt(T))\n    term2 = q * S * np.exp(-q * T) * norm.cdf(d1)\n    term3 = -r * K * np.exp(-r * T) * norm.cdf(d2)\n    return (term1 + term2 + term3) / 365.0\n\ndef implied_vol_call(market_price, S, K, T, r, q, lower=0.001, upper=5.0):\n    \"\"\"\n    Invert the BS formula to find implied volatility from a market call price.\n    Uses Brent's method (guaranteed convergence for bracketed roots).\n    \"\"\"\n    intrinsic = max(S * np.exp(-q * T) - K * np.exp(-r * T), 0)\n    if market_price <= intrinsic + 1e-10:\n        return np.nan\n    \n    def objective(sigma):\n        return bs_call_price(S, K, T, r, q, sigma) - market_price\n    \n    try:\n        if objective(lower) * objective(upper) > 0:\n            return np.nan\n        return brentq(objective, lower, upper, xtol=1e-12, maxiter=200)\n    except (ValueError, RuntimeError):\n        return np.nan\n\ndef implied_vol_put(market_price, S, K, T, r, q, lower=0.001, upper=5.0):\n    \"\"\"Invert BS for implied vol from a market put price.\"\"\"\n    # Convert to call price via put-call parity, then solve\n    call_price = market_price + S * np.exp(-q * T) - K * np.exp(-r * T)\n    return implied_vol_call(call_price, S, K, T, r, q, lower, upper)\n\nprint(\"Black-Scholes pricing functions defined (including Greeks: delta, gamma, theta).\")"
  },
  {
   "cell_type": "markdown",
   "id": "44520970",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": "## Step 1: Fetch Market Data"
  },
  {
   "cell_type": "code",
   "id": "ytfnoeu5jer",
   "source": "# --- Configuration ---\nTICKER = \"SPY\"\nTARGET_DTE = 30  # Target ~30 days to expiry\n\n# Market parameters (approximate current values)\nRISK_FREE_RATE = 0.043   # ~4.3% (3-month T-bill yield)\nDIVIDEND_YIELD = 0.013   # ~1.3% (SPY trailing dividend yield)\n\n# --- Fetch underlying price ---\nspy = yf.Ticker(TICKER)\nhist = spy.history(period=\"5d\")\nS0 = hist['Close'].iloc[-1]\nprint(f\"Underlying: {TICKER}\")\nprint(f\"Current price (S0): ${S0:.2f}\")\n\n# --- Select the nearest expiry to our target DTE ---\nexpiry_dates = spy.options\nprint(f\"\\nAvailable expiries: {len(expiry_dates)}\")\n\nfrom datetime import datetime, timedelta\ntoday = datetime.today()\ntarget_date = today + timedelta(days=TARGET_DTE)\n\n# Find expiry closest to target\nexpiry_dtes = []\nfor exp_str in expiry_dates:\n    exp_date = datetime.strptime(exp_str, \"%Y-%m-%d\")\n    dte = (exp_date - today).days\n    expiry_dtes.append((exp_str, dte, abs(dte - TARGET_DTE)))\n\nexpiry_dtes.sort(key=lambda x: x[2])\nselected_expiry = expiry_dtes[0][0]\nactual_dte = expiry_dtes[0][1]\nT = actual_dte / 365.0  # Time to expiry in years\n\nprint(f\"Selected expiry: {selected_expiry} ({actual_dte} DTE)\")\nprint(f\"T = {T:.4f} years\")\n\n# --- Fetch option chain ---\nchain = spy.option_chain(selected_expiry)\ncalls_raw = chain.calls.copy()\nputs_raw = chain.puts.copy()\n\nprint(f\"\\nRaw calls: {len(calls_raw)} strikes\")\nprint(f\"Raw puts:  {len(puts_raw)} strikes\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run Metadata ---\n",
    "from datetime import datetime\n",
    "print(\"=\" * 60)\n",
    "print(\"RUN METADATA\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Run date:        {datetime.today().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(f\"Ticker:          {TICKER}\")\n",
    "print(f\"Spot price:      ${S0:.2f}\")\n",
    "print(f\"Selected expiry: {selected_expiry}\")\n",
    "print(f\"DTE:             {actual_dte} days\")\n",
    "print(f\"T (years):       {T:.4f}\")\n",
    "print(f\"Risk-free rate:  {RISK_FREE_RATE:.3%}\")\n",
    "print(f\"Dividend yield:  {DIVIDEND_YIELD:.3%}\")\n",
    "print(f\"Forward price:   ${S0 * np.exp((RISK_FREE_RATE - DIVIDEND_YIELD) * T):.2f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cakb9shp",
   "source": "## Step 2: Clean and Filter Option Data\n\nWe need to:\n- Use **mid prices** (average of bid/ask) to reduce microstructure noise\n- Filter out illiquid options (zero bid, wide spreads, low volume/OI)\n- Focus on strikes within a reasonable range around ATM (moneyness 0.7-1.3)\n- Use **OTM options only**: OTM puts for strikes below ATM, OTM calls for strikes above ATM  \n  (OTM options are more liquid and have tighter spreads than their ITM counterparts)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "n1hx8xz9n2i",
   "source": "def clean_options(df, option_type, S, min_price=0.05, min_oi=10, moneyness_range=(0.70, 1.30)):\n    \"\"\"\n    Clean and filter option data.\n    \n    Handles both live market (bid/ask available) and after-hours (lastPrice only).\n    \"\"\"\n    df = df.copy()\n    \n    # Use mid price if bid/ask are available, otherwise fall back to lastPrice\n    has_quotes = (df['bid'] > 0) & (df['ask'] > 0)\n    df['mid'] = np.where(has_quotes, (df['bid'] + df['ask']) / 2, df['lastPrice'])\n    df['spread'] = np.where(has_quotes, df['ask'] - df['bid'], np.nan)\n    df['moneyness'] = df['strike'] / S\n    df['has_live_quotes'] = has_quotes\n    \n    # Filter\n    mask = (\n        (df['mid'] >= min_price) &\n        (df['openInterest'] >= min_oi) &\n        (df['moneyness'] >= moneyness_range[0]) &\n        (df['moneyness'] <= moneyness_range[1])\n    )\n    df = df[mask].copy()\n    \n    return df[['strike', 'bid', 'ask', 'mid', 'spread', 'lastPrice', 'volume', \n               'openInterest', 'impliedVolatility', 'moneyness', 'has_live_quotes']].sort_values('strike')\n\n# Clean both chains\ncalls = clean_options(calls_raw, 'call', S0)\nputs = clean_options(puts_raw, 'put', S0)\n\nquote_status = \"LIVE bid/ask\" if calls['has_live_quotes'].any() else \"lastPrice (market closed)\"\nprint(f\"Price source: {quote_status}\")\nprint(f\"Filtered calls: {len(calls)} strikes\")\nprint(f\"Filtered puts:  {len(puts)} strikes\")\nif len(calls) > 0:\n    print(f\"\\nCalls strike range: ${calls['strike'].min():.0f} - ${calls['strike'].max():.0f}\")\nif len(puts) > 0:\n    print(f\"Puts strike range:  ${puts['strike'].min():.0f} - ${puts['strike'].max():.0f}\")\nprint(f\"ATM strike ~ ${S0:.0f}\")\n\n# Preview\nprint(\"\\n--- Sample Calls (near ATM) ---\")\natm_mask = (calls['moneyness'] > 0.97) & (calls['moneyness'] < 1.03)\nprint(calls[atm_mask][['strike', 'mid', 'openInterest', 'moneyness']].to_string(index=False))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dk5lldmtt3e",
   "source": "## Step 3: Compute Implied Volatilities and Build the Volatility Smile\n\nWe compute IV by **inverting the Black-Scholes formula** using Brent's root-finding method.\n\nFor the smile construction, we follow market convention:\n- Use **OTM puts** for K < S (lower strikes) and **OTM calls** for K > S (upper strikes)\n- At-the-money, we average both\n\nThis gives us the cleanest implied volatility surface since OTM options are more liquid.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "75cuw6mrdsg",
   "source": "r = RISK_FREE_RATE\nq = DIVIDEND_YIELD\n\n# Compute implied vols from market mid prices\ncall_ivs = []\nfor _, row in calls.iterrows():\n    iv = implied_vol_call(row['mid'], S0, row['strike'], T, r, q)\n    call_ivs.append(iv)\ncalls = calls.copy()\ncalls['iv_computed'] = call_ivs\n\nput_ivs = []\nfor _, row in puts.iterrows():\n    iv = implied_vol_put(row['mid'], S0, row['strike'], T, r, q)\n    put_ivs.append(iv)\nputs = puts.copy()\nputs['iv_computed'] = put_ivs\n\n# Drop failed IV computations\ncalls = calls.dropna(subset=['iv_computed'])\nputs = puts.dropna(subset=['iv_computed'])\n\nprint(f\"Valid IVs: {len(calls)} calls, {len(puts)} puts\")\n\n# Build combined smile: OTM puts (K < S0) + OTM calls (K >= S0)\notm_puts = puts[puts['strike'] < S0][['strike', 'iv_computed', 'moneyness']].copy()\notm_puts = otm_puts.rename(columns={'iv_computed': 'iv'})\notm_puts['source'] = 'OTM Put'\n\notm_calls = calls[calls['strike'] >= S0][['strike', 'iv_computed', 'moneyness']].copy()\notm_calls = otm_calls.rename(columns={'iv_computed': 'iv'})\notm_calls['source'] = 'OTM Call'\n\nsmile = pd.concat([otm_puts, otm_calls], ignore_index=True).sort_values('strike')\nsmile = smile.drop_duplicates(subset='strike', keep='first')\n\n# Remove any extreme outliers (IV > 1.5 or < 0.01)\nsmile = smile[(smile['iv'] > 0.01) & (smile['iv'] < 1.5)]\n\nprint(f\"Volatility smile: {len(smile)} data points\")\nif len(smile) > 0:\n    print(f\"Strike range: ${smile['strike'].min():.0f} - ${smile['strike'].max():.0f}\")\n    print(f\"IV range: {smile['iv'].min():.4f} - {smile['iv'].max():.4f}\")\n    atm_idx = smile['moneyness'].sub(1).abs().idxmin()\n    print(f\"ATM IV ~ {smile.loc[atm_idx, 'iv']:.4f} ({smile.loc[atm_idx, 'iv']*100:.2f}%)\")\nelse:\n    print(\"WARNING: No valid smile data points. Check data source.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ghr51ztfzo",
   "source": [
    "# --- Plot the raw volatility smile ---\n",
    "fig = go.Figure()\n",
    "\n",
    "# Color by source\n",
    "for source, color in [('OTM Put', '#EF553B'), ('OTM Call', '#636EFA')]:\n",
    "    mask = smile['source'] == source\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=smile[mask]['moneyness'],\n",
    "        y=smile[mask]['iv'] * 100,\n",
    "        mode='markers',\n",
    "        name=source,\n",
    "        marker=dict(size=7, color=color),\n",
    "        hovertemplate='K=$%{customdata[0]:.0f}<br>Moneyness=%{x:.3f}<br>IV=%{y:.2f}%',\n",
    "        customdata=smile[mask][['strike']].values\n",
    "    ))\n",
    "\n",
    "fig.add_vline(x=1.0, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"ATM\")\n",
    "fig.update_layout(\n",
    "    title=f\"Implied Volatility Smile - {TICKER} ({selected_expiry}, {actual_dte} DTE)\",\n",
    "    xaxis_title=\"Moneyness (K/S)\",\n",
    "    yaxis_title=\"Implied Volatility (%)\",\n",
    "    template=\"plotly_white\",\n",
    "    width=900, height=500,\n",
    "    legend=dict(x=0.02, y=0.98)\n",
    ")\n",
    "fig.show()\n",
    "save_plotly_figure(fig, \"01_volatility_smile_raw\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "tj7ko217lye",
   "source": "## Step 4: Interpolate and Extrapolate the Volatility Smile\n\nFollowing **Malz (2014, Sec. 2.1\u20132.2)**, we fit a **clamped cubic spline** to the implied volatility data:\n\n- **Clamped** means the first derivative is set to zero at the boundary knots (Malz 2014, Eq. 5\u20136). This ensures \n  flat extrapolation beyond the observed strikes, which prevents no-arbitrage violations \n  (the call valuation function stays monotonically decreasing and convex).\n- **Cubic spline** ensures C\u00b2 continuity (continuous first and second derivatives), which is \n  essential since the BL method requires the second derivative of call prices \n  (Breeden & Litzenberger 1978, Eq. 2; Jackwerth 2004, Eq. 7).\n- Beyond observed strikes, we extrapolate at constant IV (flat wings).\n\nThe resulting **call valuation function** is defined as (Malz 2014, Eq. 4):\n\n$$c(t, X, \\tau) = v[S_t, X, \\tau, \\sigma(X), r, q]$$\n\nwhere $v[\\cdot]$ is the Black-Scholes formula and $\\sigma(X)$ is the interpolated smile.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "c21xz3otz3c",
   "source": [
    "# --- Fit clamped cubic spline to the volatility smile ---\n",
    "strikes_data = smile['strike'].values\n",
    "ivs_data = smile['iv'].values\n",
    "\n",
    "# Clamped cubic spline: first derivative = 0 at boundaries (flat extrapolation)\n",
    "# bc_type=((1, 0), (1, 0)) means first derivative = 0 at both endpoints\n",
    "vol_spline = CubicSpline(strikes_data, ivs_data, bc_type=((1, 0.0), (1, 0.0)))\n",
    "\n",
    "# Define the interpolated/extrapolated vol function with flat wings\n",
    "K_min_data = strikes_data[0]\n",
    "K_max_data = strikes_data[-1]\n",
    "iv_min = ivs_data[0]\n",
    "iv_max = ivs_data[-1]\n",
    "\n",
    "def sigma_interp(K):\n",
    "    \"\"\"\n",
    "    Interpolated implied volatility function.\n",
    "    - Inside observed range: clamped cubic spline\n",
    "    - Outside observed range: flat extrapolation at boundary IV\n",
    "    \"\"\"\n",
    "    K = np.atleast_1d(K)\n",
    "    result = np.empty_like(K, dtype=float)\n",
    "    \n",
    "    below = K < K_min_data\n",
    "    above = K > K_max_data\n",
    "    inside = ~below & ~above\n",
    "    \n",
    "    result[below] = iv_min\n",
    "    result[above] = iv_max\n",
    "    result[inside] = vol_spline(K[inside])\n",
    "    \n",
    "    # Ensure IV is always positive\n",
    "    result = np.maximum(result, 0.001)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# --- Build the call valuation function on a fine grid ---\n",
    "# This is the key: c(t, X, tau) = v(S, X, tau, sigma(X), r, q)\n",
    "# where sigma(X) comes from the interpolated smile\n",
    "\n",
    "# Fine grid extending well beyond observed strikes\n",
    "F = S0 * np.exp((r - q) * T)  # Forward price\n",
    "K_low = S0 * 0.50    # 50% of spot\n",
    "K_high = S0 * 1.50   # 150% of spot\n",
    "N_grid = 2000\n",
    "K_fine = np.linspace(K_low, K_high, N_grid)\n",
    "\n",
    "# Compute interpolated vols and call prices on fine grid\n",
    "sigma_fine = sigma_interp(K_fine)\n",
    "C_fine = bs_call_price(S0, K_fine, T, r, q, sigma_fine)\n",
    "\n",
    "print(f\"Forward price: F = ${F:.2f}\")\n",
    "print(f\"Fine grid: {N_grid} points from ${K_low:.0f} to ${K_high:.0f}\")\n",
    "print(f\"Grid spacing: dK = ${(K_high - K_low) / N_grid:.4f}\")\n",
    "\n",
    "# --- Plot: Interpolated smile overlaid on raw data ---\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=smile['strike'], y=smile['iv'] * 100,\n",
    "    mode='markers', name='Market IV (raw)',\n",
    "    marker=dict(size=7, color='#EF553B')\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=K_fine, y=sigma_fine * 100,\n",
    "    mode='lines', name='Clamped Cubic Spline',\n",
    "    line=dict(color='#636EFA', width=2)\n",
    "))\n",
    "\n",
    "fig.add_vline(x=S0, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"Spot\")\n",
    "fig.add_vline(x=K_min_data, line_dash=\"dot\", line_color=\"orange\", annotation_text=\"Data min\")\n",
    "fig.add_vline(x=K_max_data, line_dash=\"dot\", line_color=\"orange\", annotation_text=\"Data max\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Volatility Smile: Raw Data vs Clamped Cubic Spline\",\n",
    "    xaxis_title=\"Strike Price ($)\",\n",
    "    yaxis_title=\"Implied Volatility (%)\",\n",
    "    template=\"plotly_white\",\n",
    "    width=900, height=500\n",
    ")\n",
    "fig.show()\n",
    "save_plotly_figure(fig, \"02_volatility_smile_spline_fit\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "w3oek93bcob",
   "source": [
    "# --- Plot the call valuation function ---\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=K_fine, y=C_fine,\n",
    "    mode='lines', name='Call Price c(K)',\n",
    "    line=dict(color='#636EFA', width=2)\n",
    "))\n",
    "\n",
    "# Overlay actual market mid prices for calls\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=calls['strike'], y=calls['mid'],\n",
    "    mode='markers', name='Market Call Prices',\n",
    "    marker=dict(size=5, color='#EF553B')\n",
    "))\n",
    "\n",
    "fig.add_vline(x=S0, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"Spot\")\n",
    "fig.update_layout(\n",
    "    title=\"Call Valuation Function c(K) from Interpolated Smile\",\n",
    "    xaxis_title=\"Strike Price ($)\",\n",
    "    yaxis_title=\"Call Price ($)\",\n",
    "    template=\"plotly_white\",\n",
    "    width=900, height=500\n",
    ")\n",
    "fig.show()\n",
    "save_plotly_figure(fig, \"03_call_valuation_function\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "lrmuhrzohf9",
   "source": "## Step 5: Breeden-Litzenberger \u2014 Extract the Risk-Neutral Distribution\n\nThis is the core result. From the **Breeden-Litzenberger (1978) Theorem 1**, also presented as **Jackwerth (2004, Eq. 7)** and **Malz (2014, Eq. 2\u20133)**:\n\n**Risk-neutral CDF** (Malz 2014, Eq. 2):\n\n$$\\tilde{\\Pi}_t(X) = 1 + e^{r\\tau} \\frac{\\partial c}{\\partial X}$$\n\n**Risk-neutral PDF** (Breeden & Litzenberger 1978, Eq. 2; Malz 2014, Eq. 3):\n\n$$\\tilde{\\pi}_t(X) = e^{r\\tau} \\frac{\\partial^2 c}{\\partial X^2}$$\n\nWe approximate these with **central finite differences** (Malz 2014, Sec. 2.3):\n\n$$\\tilde{\\Pi}_t(X) \\approx 1 + e^{r\\tau} \\frac{1}{\\Delta}\\left[c\\left(X + \\tfrac{\\Delta}{2}\\right) - c\\left(X - \\tfrac{\\Delta}{2}\\right)\\right]$$\n\n$$\\tilde{\\pi}_t(X) \\approx e^{r\\tau} \\frac{1}{\\Delta^2}\\left[c(X + \\Delta) + c(X - \\Delta) - 2\\,c(X)\\right]$$\n\nThe second formula is the **butterfly spread** decomposition \u2014 in the limit $\\Delta \\to 0$, the butterfly payoff converges to an Arrow-Debreu security (Breeden & Litzenberger 1978, Theorem 1).\n\nThe step size $\\Delta$ is a smoothing parameter (Malz 2014, Sec. 2.4) \u2014 too small and noise dominates, too large and we lose resolution. We use $\\Delta = 0.025 \\times F$.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "oxmfsanupa",
   "source": "def call_value(K_arr):\n    \"\"\"\n    Compute BS call prices at arbitrary strikes using the interpolated vol smile.\n    This is the call valuation function c(t, X, tau) from Malz (2014) eq. (4).\n    \"\"\"\n    K_arr = np.atleast_1d(K_arr)\n    sigmas = sigma_interp(K_arr)\n    return bs_call_price(S0, K_arr, T, r, q, sigmas)\n\ndef breeden_litzenberger(K_grid, delta_frac=0.025):\n    \"\"\"\n    Apply the Breeden-Litzenberger method to extract:\n    - Risk-neutral CDF (cumulative distribution)\n    - Risk-neutral PDF (probability density)\n    \n    Parameters:\n        K_grid     : Array of strike prices to evaluate\n        delta_frac : Step size as fraction of forward price (Malz 2014 recommends ~0.025)\n    \n    Returns:\n        K_grid : Strike prices\n        cdf    : Risk-neutral CDF at each strike\n        pdf    : Risk-neutral PDF at each strike\n    \"\"\"\n    Delta = delta_frac * F  # Absolute step size in dollars\n    discount = np.exp(r * T)  # Future value factor\n    \n    # --- CDF via first derivative (central difference) ---\n    c_up_half = call_value(K_grid + Delta / 2)\n    c_dn_half = call_value(K_grid - Delta / 2)\n    cdf = 1.0 + discount * (c_up_half - c_dn_half) / Delta\n    \n    # --- PDF via second derivative (central difference) ---\n    c_center = call_value(K_grid)\n    c_up = call_value(K_grid + Delta)\n    c_dn = call_value(K_grid - Delta)\n    pdf = discount * (c_up + c_dn - 2.0 * c_center) / (Delta**2)\n    \n    return K_grid, cdf, pdf\n\n# --- Compute the RND ---\nK_rnd = np.linspace(S0 * 0.70, S0 * 1.30, 1500)\n_, rn_cdf, rn_pdf = breeden_litzenberger(K_rnd, delta_frac=0.025)\n\n# Ensure non-negative densities (numerical artifact cleanup)\nrn_pdf = np.maximum(rn_pdf, 0)\n\n# Normalise the PDF so it integrates to 1 (numerical correction)\ntotal_mass = trapz(rn_pdf, K_rnd)\nrn_pdf_norm = rn_pdf / total_mass\n\nprint(f\"Step size Delta = {0.025 * F:.2f} (= 2.5% of forward ${F:.2f})\")\nprint(f\"PDF total mass before normalisation: {total_mass:.6f}\")\nprint(f\"PDF total mass after normalisation:  {trapz(rn_pdf_norm, K_rnd):.6f}\")\nprint(f\"CDF range: [{rn_cdf.min():.4f}, {rn_cdf.max():.4f}]\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "211kfnbrckq",
   "source": "## Step 6: Lognormal Benchmark (Black-Scholes Theoretical Distribution)\n\nUnder Black-Scholes assumptions, the risk-neutral distribution of $S_T$ is **lognormal**:\n\n$$\\ln S_T \\sim \\mathcal{N}\\left(\\ln S_0 + (r - q - \\tfrac{\\sigma^2}{2})T,\\;\\; \\sigma^2 T\\right)$$\n\nWe use the ATM implied volatility as $\\sigma$ to build this benchmark. Any deviation between \nthe market-implied RND and this lognormal represents the market's view that returns are \n**not** normally distributed \u2014 revealing skew, excess kurtosis, and tail risk.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "55tch6q3zc4",
   "source": "# --- Lognormal benchmark from Black-Scholes ---\n# ATM implied vol\nsigma_atm = float(sigma_interp(np.array([S0]))[0])\nprint(f\"ATM implied volatility: {sigma_atm:.4f} ({sigma_atm*100:.2f}%)\")\n\n# Under risk-neutral measure, ln(S_T) ~ N(mu_ln, sigma_ln^2)\nmu_ln = np.log(S0) + (r - q - 0.5 * sigma_atm**2) * T\nsigma_ln = sigma_atm * np.sqrt(T)\n\n# Lognormal PDF: f(x) = (1/(x * sigma_ln * sqrt(2*pi))) * exp(-(ln(x) - mu_ln)^2 / (2*sigma_ln^2))\nlognorm_pdf = (1.0 / (K_rnd * sigma_ln * np.sqrt(2 * np.pi))) * \\\n              np.exp(-0.5 * ((np.log(K_rnd) - mu_ln) / sigma_ln)**2)\n\n# Lognormal CDF\nlognorm_cdf = norm.cdf((np.log(K_rnd) - mu_ln) / sigma_ln)\n\nprint(f\"Lognormal mean (E[S_T]): ${np.exp(mu_ln + 0.5*sigma_ln**2):.2f}\")\nprint(f\"Forward price:           ${F:.2f}\")\nprint(f\"Lognormal std dev:       ${np.exp(mu_ln + 0.5*sigma_ln**2) * np.sqrt(np.exp(sigma_ln**2) - 1):.2f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "cuzjljxq1is",
   "source": [
    "# =============================================================================\n",
    "# MAIN RESULT: Risk-Neutral Density vs Lognormal Benchmark\n",
    "# =============================================================================\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=(\n",
    "        \"Risk-Neutral PDF (Probability Density)\",\n",
    "        \"Risk-Neutral CDF (Cumulative Probability)\",\n",
    "        \"PDF Difference (Market-Implied minus Lognormal)\",\n",
    "        \"Log-Return Density\"\n",
    "    ),\n",
    "    vertical_spacing=0.12,\n",
    "    horizontal_spacing=0.08\n",
    ")\n",
    "\n",
    "# --- (1) PDF comparison ---\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=K_rnd, y=rn_pdf_norm,\n",
    "    mode='lines', name='Market-Implied RND',\n",
    "    line=dict(color='#EF553B', width=2.5),\n",
    "    legendgroup='pdf'\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=K_rnd, y=lognorm_pdf,\n",
    "    mode='lines', name='Lognormal (BS)',\n",
    "    line=dict(color='#636EFA', width=2, dash='dash'),\n",
    "    legendgroup='pdf'\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.add_vline(x=F, line_dash=\"dot\", line_color=\"gray\", row=1, col=1)\n",
    "\n",
    "# --- (2) CDF comparison ---\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=K_rnd, y=rn_cdf,\n",
    "    mode='lines', name='Market CDF',\n",
    "    line=dict(color='#EF553B', width=2.5),\n",
    "    legendgroup='cdf', showlegend=False\n",
    "), row=1, col=2)\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=K_rnd, y=lognorm_cdf,\n",
    "    mode='lines', name='Lognormal CDF',\n",
    "    line=dict(color='#636EFA', width=2, dash='dash'),\n",
    "    legendgroup='cdf', showlegend=False\n",
    "), row=1, col=2)\n",
    "\n",
    "# --- (3) PDF difference (where does the market disagree with BS?) ---\n",
    "pdf_diff = rn_pdf_norm - lognorm_pdf\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=K_rnd, y=pdf_diff,\n",
    "    mode='lines', name='Density Difference',\n",
    "    line=dict(color='#AB63FA', width=2),\n",
    "    fill='tozeroy',\n",
    "    fillcolor='rgba(171, 99, 250, 0.15)'\n",
    "), row=2, col=1)\n",
    "\n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", row=2, col=1)\n",
    "fig.add_vline(x=F, line_dash=\"dot\", line_color=\"gray\", row=2, col=1)\n",
    "\n",
    "# --- (4) Log-return density ---\n",
    "# Transform from price space to return space: R = ln(S_T / S_0)\n",
    "returns = np.log(K_rnd / S0) * 100  # Percentage log returns\n",
    "\n",
    "# Transform PDF: f_R(r) = S_0 * exp(r) * f_S(S_0 * exp(r))\n",
    "# But since we already have pdf on K grid, just replot vs returns\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=returns, y=rn_pdf_norm * K_rnd,  # Jacobian: dK = K * dR\n",
    "    mode='lines', name='Market (Returns)',\n",
    "    line=dict(color='#EF553B', width=2.5),\n",
    "    showlegend=False\n",
    "), row=2, col=2)\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=returns, y=lognorm_pdf * K_rnd,\n",
    "    mode='lines', name='Lognormal (Returns)',\n",
    "    line=dict(color='#636EFA', width=2, dash='dash'),\n",
    "    showlegend=False\n",
    "), row=2, col=2)\n",
    "\n",
    "fig.add_vline(x=0, line_dash=\"dot\", line_color=\"gray\", row=2, col=2)\n",
    "\n",
    "# Layout\n",
    "fig.update_xaxes(title_text=\"Strike Price ($)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Strike Price ($)\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Strike Price ($)\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Log Return (%)\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"Density\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Probability\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Density Diff\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Density\", row=2, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Breeden-Litzenberger Risk-Neutral Distribution \u2014 {TICKER} ({selected_expiry}, {actual_dte} DTE)\",\n",
    "    template=\"plotly_white\",\n",
    "    width=1100, height=800,\n",
    "    showlegend=True,\n",
    "    legend=dict(x=0.02, y=0.98)\n",
    ")\n",
    "fig.show()\n",
    "save_plotly_figure(fig, \"04_risk_neutral_distribution\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "hqz55ozok2b",
   "source": "## Step 7: Statistical Analysis \u2014 Moments, Tail Risk, and Skewness\n\nWe compute the first four moments of the market-implied distribution and compare them \nto the lognormal benchmark. Key metrics:\n- **Mean**: Expected future price under the risk-neutral measure (should match the forward price)\n- **Variance/Std**: Width of the distribution\n- **Skewness**: Asymmetry \u2014 negative skew means the market prices in larger downside moves\n- **Excess Kurtosis**: Fat tails \u2014 positive means the market expects more extreme moves than lognormal\n- **Tail probabilities**: Probability of large declines (e.g., -10%, -20%)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "kqz4oycld2n",
   "source": "def compute_moments(K, pdf_vals):\n    \"\"\"Compute moments of a distribution given on a discrete grid.\"\"\"\n    total = trapz(pdf_vals, K)\n    f = pdf_vals / total\n    \n    mean = trapz(K * f, K)\n    var = trapz((K - mean)**2 * f, K)\n    std = np.sqrt(var)\n    skew = trapz(((K - mean) / std)**3 * f, K)\n    kurt = trapz(((K - mean) / std)**4 * f, K) - 3.0\n    \n    return {'mean': mean, 'std': std, 'variance': var, 'skewness': skew, 'excess_kurtosis': kurt}\n\n# Compute moments for both distributions\nmarket_moments = compute_moments(K_rnd, rn_pdf_norm)\nlognorm_moments = compute_moments(K_rnd, lognorm_pdf)\n\n# --- Display comparison table ---\nprint(\"=\" * 70)\nprint(f\"  DISTRIBUTION MOMENTS COMPARISON \u2014 {TICKER} ({selected_expiry})\")\nprint(\"=\" * 70)\nprint(f\"{'Statistic':<25} {'Market-Implied':>18} {'Lognormal (BS)':>18}\")\nprint(\"-\" * 70)\nprint(f\"{'Mean E[S_T]':<25} ${market_moments['mean']:>17.2f} ${lognorm_moments['mean']:>17.2f}\")\nprint(f\"{'Std Dev':<25} ${market_moments['std']:>17.2f} ${lognorm_moments['std']:>17.2f}\")\nprint(f\"{'Skewness':<25} {market_moments['skewness']:>18.4f} {lognorm_moments['skewness']:>18.4f}\")\nprint(f\"{'Excess Kurtosis':<25} {market_moments['excess_kurtosis']:>18.4f} {lognorm_moments['excess_kurtosis']:>18.4f}\")\nprint(f\"{'Forward Price':<25} ${F:>17.2f}\")\nprint(\"-\" * 70)\n\n# --- Tail probabilities ---\nprint(f\"\\n{'TAIL RISK ANALYSIS':^70}\")\nprint(\"=\" * 70)\nprint(f\"{'Event':<35} {'Market Prob':>15} {'Lognormal Prob':>15}\")\nprint(\"-\" * 70)\n\nfor pct_decline in [-5, -10, -15, -20, -25]:\n    K_level = S0 * (1 + pct_decline / 100)\n    mask = K_rnd <= K_level\n    mkt_prob = trapz(rn_pdf_norm[mask], K_rnd[mask]) if mask.any() else 0.0\n    ln_prob = norm.cdf((np.log(K_level) - mu_ln) / sigma_ln)\n    label = f\"Decline >= {abs(pct_decline)}% (S_T < ${K_level:.0f})\"\n    print(f\"{label:<35} {mkt_prob:>14.4%} {ln_prob:>14.4%}\")\n\nprint()\nfor pct_gain in [5, 10, 15, 20]:\n    K_level = S0 * (1 + pct_gain / 100)\n    mask = K_rnd >= K_level\n    mkt_prob = trapz(rn_pdf_norm[mask], K_rnd[mask]) if mask.any() else 0.0\n    ln_prob = 1.0 - norm.cdf((np.log(K_level) - mu_ln) / sigma_ln)\n    label = f\"Gain >= {pct_gain}% (S_T > ${K_level:.0f})\"\n    print(f\"{label:<35} {mkt_prob:>14.4%} {ln_prob:>14.4%}\")\n\nprint(\"=\" * 70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "nds5sq393se",
   "source": "## Step 8: Sensitivity to the Smoothing Parameter $\\Delta$\n\nThe finite difference step size $\\Delta$ trades off resolution vs smoothness (Malz 2014, Sec. 2.4). \nMalz recommends $\\Delta = \\alpha \\cdot F$ with $\\alpha \\approx 0.025$ as a baseline. \nWe show how the extracted density changes for different values of $\\alpha \\in \\{0.01, 0.025, 0.05, 0.10\\}$.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "g6zia58syqp",
   "source": [
    "# --- Sensitivity to Delta ---\n",
    "fig = go.Figure()\n",
    "\n",
    "delta_fracs = [0.010, 0.025, 0.050, 0.100]\n",
    "colors = ['#FF6692', '#EF553B', '#636EFA', '#00CC96']\n",
    "\n",
    "for delta_frac, color in zip(delta_fracs, colors):\n",
    "    _, _, pdf_test = breeden_litzenberger(K_rnd, delta_frac=delta_frac)\n",
    "    pdf_test = np.maximum(pdf_test, 0)\n",
    "    pdf_test = pdf_test / trapz(pdf_test, K_rnd)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=K_rnd, y=pdf_test,\n",
    "        mode='lines',\n",
    "        name=f'Delta = {delta_frac:.3f} (${delta_frac * F:.1f})',\n",
    "        line=dict(color=color, width=2)\n",
    "    ))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=K_rnd, y=lognorm_pdf,\n",
    "    mode='lines', name='Lognormal (BS)',\n",
    "    line=dict(color='gray', width=1.5, dash='dash')\n",
    "))\n",
    "\n",
    "fig.add_vline(x=F, line_dash=\"dot\", line_color=\"lightgray\")\n",
    "fig.update_layout(\n",
    "    title=f\"Sensitivity of Risk-Neutral Density to Step Size Delta\",\n",
    "    xaxis_title=\"Strike Price ($)\",\n",
    "    yaxis_title=\"Density\",\n",
    "    template=\"plotly_white\",\n",
    "    width=900, height=500,\n",
    "    legend=dict(x=0.70, y=0.98)\n",
    ")\n",
    "fig.show()\n",
    "save_plotly_figure(fig, \"05_sensitivity_delta\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bv0hr36vwxs",
   "source": "## Step 9: Tail Risk Visualisation\n\nHighlight where the market prices significantly more or less probability than the \nlognormal model. The **left tail** (large declines) is typically heavier in market-implied \ndistributions \u2014 this is the **volatility skew** in action.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "0bjckboi8rqf",
   "source": [
    "# --- Tail risk: shaded area comparison ---\n",
    "fig = go.Figure()\n",
    "\n",
    "# Full distributions\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=K_rnd, y=rn_pdf_norm,\n",
    "    mode='lines', name='Market-Implied',\n",
    "    line=dict(color='#EF553B', width=2.5)\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=K_rnd, y=lognorm_pdf,\n",
    "    mode='lines', name='Lognormal (BS)',\n",
    "    line=dict(color='#636EFA', width=2, dash='dash')\n",
    "))\n",
    "\n",
    "# Shade left tail (decline > 10%)\n",
    "K_left_tail = S0 * 0.90\n",
    "left_mask = K_rnd <= K_left_tail\n",
    "if left_mask.any():\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=K_rnd[left_mask], y=rn_pdf_norm[left_mask],\n",
    "        fill='tozeroy', fillcolor='rgba(239, 85, 59, 0.3)',\n",
    "        line=dict(width=0), showlegend=True,\n",
    "        name=f'Market left tail (>{10}% decline)'\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=K_rnd[left_mask], y=lognorm_pdf[left_mask],\n",
    "        fill='tozeroy', fillcolor='rgba(99, 110, 250, 0.15)',\n",
    "        line=dict(width=0), showlegend=True,\n",
    "        name=f'Lognormal left tail'\n",
    "    ))\n",
    "\n",
    "# Shade right tail (gain > 10%)\n",
    "K_right_tail = S0 * 1.10\n",
    "right_mask = K_rnd >= K_right_tail\n",
    "if right_mask.any():\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=K_rnd[right_mask], y=rn_pdf_norm[right_mask],\n",
    "        fill='tozeroy', fillcolor='rgba(0, 204, 150, 0.3)',\n",
    "        line=dict(width=0), showlegend=True,\n",
    "        name=f'Market right tail (>{10}% gain)'\n",
    "    ))\n",
    "\n",
    "fig.add_vline(x=S0, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"Current Price\")\n",
    "fig.add_vline(x=K_left_tail, line_dash=\"dot\", line_color=\"#EF553B\", annotation_text=\"-10%\")\n",
    "fig.add_vline(x=K_right_tail, line_dash=\"dot\", line_color=\"#00CC96\", annotation_text=\"+10%\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Tail Risk: Market-Implied vs Lognormal \u2014 {TICKER}\",\n",
    "    xaxis_title=\"Strike Price ($)\",\n",
    "    yaxis_title=\"Density\",\n",
    "    template=\"plotly_white\",\n",
    "    width=1000, height=550,\n",
    "    legend=dict(x=0.65, y=0.98)\n",
    ")\n",
    "fig.show()\n",
    "save_plotly_figure(fig, \"06_tail_risk\")\n",
    "\n",
    "# --- Print tail probability ratios ---\n",
    "print(\"\\nTAIL PROBABILITY RATIOS (Market / Lognormal):\")\n",
    "print(\"=\" * 50)\n",
    "for pct in [5, 10, 15, 20]:\n",
    "    K_lev = S0 * (1 - pct / 100)\n",
    "    mask = K_rnd <= K_lev\n",
    "    if mask.any():\n",
    "        mkt_p = trapz(rn_pdf_norm[mask], K_rnd[mask])\n",
    "        ln_p = norm.cdf((np.log(K_lev) - mu_ln) / sigma_ln)\n",
    "        ratio = mkt_p / ln_p if ln_p > 0 else float('inf')\n",
    "        print(f\"  {pct}% decline: Market = {mkt_p:.4%}, Lognormal = {ln_p:.4%}, Ratio = {ratio:.2f}x\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nRatios > 1 mean the market prices MORE probability of that tail event than BS assumes.\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "v0a814wf36",
   "source": "## Step 10: Diagnostics and Quality Checks\n\nFollowing **Malz (2014, Sec. 2.5)**, we verify our extraction is sensible:\n1. The CDF should range from ~0 to ~1 (valid probability distribution)\n2. The PDF should be non-negative everywhere (no butterfly arbitrage)\n3. The mean of the RND should approximate the forward price (no-arbitrage, see Malz 2014, Eq. 2\u20133)\n4. Exercise-price deltas at the extremes should be close to 0 and $-e^{-r\\tau}$ (Malz 2014, Sec. 2.5)\n5. Low vega at data boundaries ensures flat extrapolation has minimal impact",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "rdxrq0zuqlp",
   "source": "# --- Diagnostics ---\nprint(\"DIAGNOSTIC CHECKS\")\nprint(\"=\" * 60)\n\n# 1. CDF bounds\nprint(f\"\\n1. CDF bounds:\")\nprint(f\"   CDF at lowest strike  (K={K_rnd[0]:.0f}):  {rn_cdf[0]:.6f}  (should be ~0)\")\nprint(f\"   CDF at highest strike (K={K_rnd[-1]:.0f}): {rn_cdf[-1]:.6f}  (should be ~1)\")\n\n# 2. PDF non-negativity\nneg_count = np.sum(rn_pdf < 0)\nneg_pct = neg_count / len(rn_pdf) * 100\nprint(f\"\\n2. PDF non-negativity:\")\nprint(f\"   Negative density points: {neg_count}/{len(rn_pdf)} ({neg_pct:.1f}%)\")\nif neg_count > 0:\n    print(f\"   Max negative density: {rn_pdf.min():.8f}\")\n    print(f\"   (These are set to 0 in the normalised PDF)\")\n\n# 3. Mean vs forward price\nmean_err = abs(market_moments['mean'] - F) / F * 100\nprint(f\"\\n3. No-arbitrage mean check:\")\nprint(f\"   RND mean E[S_T]:  ${market_moments['mean']:.2f}\")\nprint(f\"   Forward price F:  ${F:.2f}\")\nprint(f\"   Error:            {mean_err:.4f}%\")\n\n# 4. Exercise-price deltas at data boundaries\n# Delta of call at lowest observed strike (should be near -1, i.e., deep ITM call)\nd1_low = bs_d1(S0, K_min_data, T, r, q, sigma_interp(np.array([K_min_data]))[0])\ndelta_low = -np.exp(-r * T) * norm.cdf(-d1_low + sigma_interp(np.array([K_min_data]))[0] * np.sqrt(T))\n# Simpler: exercise-price delta \u2248 \u2202c/\u2202X\neps = 0.01\ndelta_ex_low = (call_value(np.array([K_min_data + eps])) - call_value(np.array([K_min_data - eps]))) / (2 * eps)\ndelta_ex_high = (call_value(np.array([K_max_data + eps])) - call_value(np.array([K_max_data - eps]))) / (2 * eps)\n\nprint(f\"\\n4. Exercise-price deltas at data boundaries:\")\nprint(f\"   \u2202c/\u2202X at K_min (${K_min_data:.0f}): {delta_ex_low[0]:.4f}  (should be near -e^{{-r\u03c4}} = {-np.exp(-r*T):.4f})\")\nprint(f\"   \u2202c/\u2202X at K_max (${K_max_data:.0f}): {delta_ex_high[0]:.4f}  (should be near 0)\")\n\n# 5. Vega at boundaries (low vega = extrapolation has less impact)\nvega_min = bs_vega(S0, K_min_data, T, r, q, sigma_interp(np.array([K_min_data]))[0])\nvega_max = bs_vega(S0, K_max_data, T, r, q, sigma_interp(np.array([K_max_data]))[0])\nvega_atm = bs_vega(S0, S0, T, r, q, sigma_atm)\n\nprint(f\"\\n5. Vega ratios (boundary vega / ATM vega):\")\nprint(f\"   Vega(K_min)/Vega(ATM): {vega_min/vega_atm:.4f}  (should be small)\")\nprint(f\"   Vega(K_max)/Vega(ATM): {vega_max/vega_atm:.4f}  (should be small)\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"All diagnostics complete.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8lznrpkzag6",
   "source": "## Step 11: Multi-Expiry Analysis \u2014 3D Implied Volatility Surface\n\nThe volatility smile varies with time to expiry, forming the **implied volatility surface** $\\sigma(X, \\tau)$.\nThis is a key object in quantitative finance \u2014 it encodes the market's full forward-looking view across\nboth strike and maturity dimensions.\n\nWe fetch multiple expiries (7\u2013180 DTE), compute implied volatilities for each, and plot the surface\nin 3D using Plotly. The surface is parameterised by **moneyness** $K/S$ (x-axis) and\n**time to expiry** in days (y-axis), with implied volatility on the z-axis.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "77pif18tesj",
   "source": "# --- Fetch multiple expiries and build vol surface data ---\nMIN_DTE, MAX_DTE = 7, 180\n\nexpiry_candidates = []\nfor exp_str in expiry_dates:\n    exp_date = datetime.strptime(exp_str, \"%Y-%m-%d\")\n    dte = (exp_date - today).days\n    if MIN_DTE <= dte <= MAX_DTE:\n        expiry_candidates.append((exp_str, dte))\n\n# Take up to 6 roughly evenly spaced expiries\nif len(expiry_candidates) > 6:\n    step = len(expiry_candidates) // 6\n    expiry_sel = [expiry_candidates[i] for i in range(0, len(expiry_candidates), step)][:6]\nelse:\n    expiry_sel = expiry_candidates\n\nprint(f\"Selected {len(expiry_sel)} expiries for surface construction:\")\nfor exp_str, dte in expiry_sel:\n    print(f\"  {exp_str}  ({dte} DTE)\")\n\ndef make_sigma_interp(smile_df):\n    \"\"\"Factory: build a clamped cubic spline sigma(K) from a smile DataFrame.\"\"\"\n    Ks = smile_df['strike'].values\n    ivs = smile_df['iv'].values\n    spline = CubicSpline(Ks, ivs, bc_type=((1, 0.0), (1, 0.0)))\n    K_lo, K_hi = Ks[0], Ks[-1]\n    iv_lo, iv_hi = ivs[0], ivs[-1]\n    def _sigma(K):\n        K = np.atleast_1d(K)\n        out = np.empty_like(K, dtype=float)\n        out[K < K_lo] = iv_lo\n        out[K > K_hi] = iv_hi\n        mask = (K >= K_lo) & (K <= K_hi)\n        out[mask] = spline(K[mask])\n        return np.maximum(out, 0.001)\n    return _sigma\n\n# Build vol surface data: list of (dte, moneyness_grid, iv_grid, smile_raw)\nsurface_data = []\n\nfor exp_str, dte in expiry_sel:\n    T_exp = dte / 365.0\n    chain_exp = spy.option_chain(exp_str)\n\n    calls_exp = clean_options(chain_exp.calls, 'call', S0)\n    puts_exp = clean_options(chain_exp.puts, 'put', S0)\n\n    # Compute IVs\n    c_ivs = [implied_vol_call(row['mid'], S0, row['strike'], T_exp, r, q)\n             for _, row in calls_exp.iterrows()]\n    calls_exp = calls_exp.copy(); calls_exp['iv_computed'] = c_ivs\n    p_ivs = [implied_vol_put(row['mid'], S0, row['strike'], T_exp, r, q)\n             for _, row in puts_exp.iterrows()]\n    puts_exp = puts_exp.copy(); puts_exp['iv_computed'] = p_ivs\n    calls_exp = calls_exp.dropna(subset=['iv_computed'])\n    puts_exp = puts_exp.dropna(subset=['iv_computed'])\n\n    # Build OTM smile\n    otm_p = puts_exp[puts_exp['strike'] < S0][['strike','iv_computed','moneyness']].rename(columns={'iv_computed':'iv'})\n    otm_c = calls_exp[calls_exp['strike'] >= S0][['strike','iv_computed','moneyness']].rename(columns={'iv_computed':'iv'})\n    smile_exp = pd.concat([otm_p, otm_c]).sort_values('strike').drop_duplicates('strike')\n    smile_exp = smile_exp[(smile_exp['iv'] > 0.01) & (smile_exp['iv'] < 1.5)]\n\n    if len(smile_exp) < 5:\n        continue\n\n    sig_fn = make_sigma_interp(smile_exp)\n\n    # Evaluate on common moneyness grid\n    m_grid = np.linspace(0.80, 1.20, 200)\n    K_grid = m_grid * S0\n    iv_grid = sig_fn(K_grid)\n\n    surface_data.append({\n        'expiry': exp_str, 'dte': dte, 'T': T_exp,\n        'moneyness': m_grid, 'iv': iv_grid,\n        'sigma_fn': sig_fn, 'smile_raw': smile_exp\n    })\n\nprint(f\"\\nBuilt surface data for {len(surface_data)} expiries.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7o4ekfbeutd",
   "source": [
    "# --- 3D Implied Volatility Surface ---\n",
    "m_common = np.linspace(0.80, 1.20, 200)\n",
    "dte_vals = np.array([d['dte'] for d in surface_data])\n",
    "iv_matrix = np.array([d['iv'] * 100 for d in surface_data])  # shape: (n_expiries, n_moneyness)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Surface\n",
    "fig.add_trace(go.Surface(\n",
    "    x=m_common, y=dte_vals, z=iv_matrix,\n",
    "    colorscale='Viridis', opacity=0.85,\n",
    "    colorbar=dict(title='IV (%)'),\n",
    "    name='IV Surface'\n",
    "))\n",
    "\n",
    "# Overlay raw data points\n",
    "for d in surface_data:\n",
    "    raw = d['smile_raw']\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=raw['moneyness'].values,\n",
    "        y=np.full(len(raw), d['dte']),\n",
    "        z=raw['iv'].values * 100,\n",
    "        mode='markers',\n",
    "        marker=dict(size=2.5, color='red'),\n",
    "        name=f\"{d['expiry']}\",\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'3D Implied Volatility Surface \u2014 {TICKER}',\n",
    "    scene=dict(\n",
    "        xaxis_title='Moneyness (K/S)',\n",
    "        yaxis_title='Days to Expiry',\n",
    "        zaxis_title='Implied Volatility (%)',\n",
    "        camera=dict(eye=dict(x=1.8, y=-1.8, z=1.0))\n",
    "    ),\n",
    "    template='plotly_white',\n",
    "    width=1000, height=700\n",
    ")\n",
    "fig.show()\n",
    "save_plotly_figure(fig, \"07_iv_surface_3d\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fhpp2v698ti",
   "source": "## Step 11b: Greeks Surfaces \u2014 Delta, Gamma, Vega, Theta\n\nThe option **Greeks** measure sensitivity to market variables. Plotting them across moneyness $\\times$ maturity reveals how risk exposures shift:\n\n- **Delta** ($\\partial C / \\partial S$): ranges 0\u20131 for calls, steepens near ATM at short maturities\n- **Gamma** ($\\partial^2 C / \\partial S^2$): peaks near ATM at short maturities (pin risk)\n- **Vega** ($\\partial C / \\partial \\sigma$): peaks near ATM at longer maturities\n- **Theta** ($\\partial C / \\partial t$): most negative near ATM at short maturities (time decay)\n\nAll Greeks are computed using **market-implied IV** (not flat vol), so the surfaces reflect the true smile.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "p5m582zauh",
   "source": [
    "# --- Greeks Surfaces: Delta, Gamma, Vega, Theta ---\n",
    "m_greeks = np.linspace(0.85, 1.15, 200)\n",
    "K_greeks = m_greeks * S0\n",
    "\n",
    "delta_matrix = []\n",
    "gamma_matrix = []\n",
    "vega_matrix = []\n",
    "theta_matrix = []\n",
    "\n",
    "for d in surface_data:\n",
    "    sigma_vals = d['sigma_fn'](K_greeks)\n",
    "    delta_matrix.append(bs_delta_call(S0, K_greeks, d['T'], r, q, sigma_vals))\n",
    "    gamma_matrix.append(bs_gamma(S0, K_greeks, d['T'], r, q, sigma_vals))\n",
    "    vega_matrix.append(bs_vega(S0, K_greeks, d['T'], r, q, sigma_vals))\n",
    "    theta_matrix.append(bs_theta_call(S0, K_greeks, d['T'], r, q, sigma_vals))\n",
    "\n",
    "delta_matrix = np.array(delta_matrix)\n",
    "gamma_matrix = np.array(gamma_matrix)\n",
    "vega_matrix = np.array(vega_matrix)\n",
    "theta_matrix = np.array(theta_matrix)\n",
    "\n",
    "greeks_config = [\n",
    "    ('Delta (Call)', delta_matrix, 'Plasma', 'Delta', '08a_greeks_delta'),\n",
    "    ('Gamma', gamma_matrix, 'Inferno', 'Gamma', '08b_greeks_gamma'),\n",
    "    ('Vega', vega_matrix, 'Viridis', 'Vega ($)', '08c_greeks_vega'),\n",
    "    ('Theta (Call, $/day)', theta_matrix, 'Cividis', 'Theta ($/day)', '08d_greeks_theta'),\n",
    "]\n",
    "\n",
    "for title_suffix, matrix, cscale, zlab, save_name in greeks_config:\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Surface(\n",
    "        x=m_greeks, y=dte_vals, z=matrix,\n",
    "        colorscale=cscale, opacity=0.85,\n",
    "        colorbar=dict(title=zlab)\n",
    "    ))\n",
    "    fig.update_layout(\n",
    "        title=f'{title_suffix} Surface \u2014 {TICKER}',\n",
    "        scene=dict(\n",
    "            xaxis_title='Moneyness (K/S)',\n",
    "            yaxis_title='Days to Expiry',\n",
    "            zaxis_title=zlab,\n",
    "            camera=dict(eye=dict(x=1.8, y=-1.8, z=1.0))\n",
    "        ),\n",
    "        template='plotly_white',\n",
    "        width=1000, height=700\n",
    "    )\n",
    "    fig.show()\n",
    "    save_plotly_figure(fig, save_name)\n",
    "\n",
    "print(f\"Greeks surfaces computed for {len(surface_data)} expiries on {len(m_greeks)}-point grid.\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "qef7b2qboom",
   "source": "## Step 11c: Volatility Skew Evolution Surface\n\nThe **skew** (first derivative of IV w.r.t. moneyness, $\\partial \\sigma / \\partial (K/S)$) measures the smile's slope \u2014 typically negative for equity indices (downside protection demand). The **curvature** (second derivative, $\\partial^2 \\sigma / \\partial (K/S)^2$) captures convexity of the smile (butterfly spread richness).\n\nPlotting these across maturity shows how skew and curvature evolve with the term structure \u2014 short-dated options typically exhibit steeper skew that flattens at longer horizons.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "b3bmgrk1kaf",
   "source": [
    "# --- Volatility Skew and Curvature Evolution Surfaces ---\n",
    "m_skew = np.linspace(0.88, 1.12, 200)\n",
    "K_skew = m_skew * S0\n",
    "dm = m_skew[1] - m_skew[0]\n",
    "\n",
    "skew_matrix = []\n",
    "curvature_matrix = []\n",
    "\n",
    "for d in surface_data:\n",
    "    iv_vals = d['sigma_fn'](K_skew) * 100  # IV in %\n",
    "    skew = np.gradient(iv_vals, dm)          # dIV/d(K/S)\n",
    "    curvature = np.gradient(skew, dm)        # d\u00b2IV/d(K/S)\u00b2\n",
    "    skew_matrix.append(skew)\n",
    "    curvature_matrix.append(curvature)\n",
    "\n",
    "skew_matrix = np.array(skew_matrix)\n",
    "curvature_matrix = np.array(curvature_matrix)\n",
    "\n",
    "# --- Skew surface ---\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Surface(\n",
    "    x=m_skew, y=dte_vals, z=skew_matrix,\n",
    "    colorscale='RdBu_r', opacity=0.85, cmid=0,\n",
    "    colorbar=dict(title='dIV/d(K/S)')\n",
    "))\n",
    "\n",
    "# ATM skew line (moneyness = 1.0)\n",
    "atm_idx = np.argmin(np.abs(m_skew - 1.0))\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=np.full(len(dte_vals), 1.0),\n",
    "    y=dte_vals,\n",
    "    z=skew_matrix[:, atm_idx],\n",
    "    mode='lines+markers',\n",
    "    marker=dict(size=3, color='black'),\n",
    "    line=dict(color='black', width=3),\n",
    "    name='ATM Skew'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Volatility Skew (dIV/dMoneyness) Surface \u2014 {TICKER}',\n",
    "    scene=dict(\n",
    "        xaxis_title='Moneyness (K/S)',\n",
    "        yaxis_title='Days to Expiry',\n",
    "        zaxis_title='Skew (%pts per unit moneyness)',\n",
    "        camera=dict(eye=dict(x=1.8, y=-1.8, z=1.0))\n",
    "    ),\n",
    "    template='plotly_white',\n",
    "    width=1000, height=700\n",
    ")\n",
    "fig.show()\n",
    "save_plotly_figure(fig, \"09a_skew_evolution\")\n",
    "\n",
    "# --- Curvature surface (clip outliers for visualization) ---\n",
    "curv_p1, curv_p99 = np.percentile(curvature_matrix, [2, 98])\n",
    "curvature_clipped = np.clip(curvature_matrix, curv_p1, curv_p99)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Surface(\n",
    "    x=m_skew, y=dte_vals, z=curvature_clipped,\n",
    "    colorscale='Viridis', opacity=0.85,\n",
    "    colorbar=dict(title='d\u00b2IV/d(K/S)\u00b2')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Volatility Curvature (d\u00b2IV/dMoneyness\u00b2) Surface \u2014 {TICKER}',\n",
    "    scene=dict(\n",
    "        xaxis_title='Moneyness (K/S)',\n",
    "        yaxis_title='Days to Expiry',\n",
    "        zaxis_title='Curvature (%pts per unit\u00b2)',\n",
    "        camera=dict(eye=dict(x=1.8, y=-1.8, z=1.0))\n",
    "    ),\n",
    "    template='plotly_white',\n",
    "    width=1000, height=700\n",
    ")\n",
    "fig.show()\n",
    "save_plotly_figure(fig, \"09b_curvature_evolution\")\n",
    "\n",
    "print(f\"Skew range: [{skew_matrix.min():.1f}, {skew_matrix.max():.1f}] %pts/moneyness\")\n",
    "print(f\"ATM skew by maturity: {dict(zip([d['dte'] for d in surface_data], skew_matrix[:, atm_idx].round(1)))}\")\n",
    "print(f\"Curvature clipped to [{curv_p1:.0f}, {curv_p99:.0f}] (p2/p98) to remove spline edge artifacts.\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "y5tfxklv6ge",
   "source": "## Step 12: 3D Risk-Neutral Density Surface\n\nApplying the Breeden-Litzenberger extraction (BL 1978, Eq. 2) to each expiry, we obtain the\n**risk-neutral density surface** $\\tilde{\\pi}(K/S, \\tau)$. This shows how the market-implied\ndistribution evolves with maturity:\n- Short-dated distributions are narrow and peaked (low total variance)\n- Longer-dated distributions spread out and typically show more pronounced skewness",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "pn62bl7ygr8",
   "source": [
    "def breeden_litzenberger_general(K_grid, S, T_exp, r_val, q_val, sigma_fn, delta_frac=0.025):\n",
    "    \"\"\"\n",
    "    Generalised BL extraction for any expiry.\n",
    "    \n",
    "    Parameters:\n",
    "        K_grid   : strike grid\n",
    "        S        : spot price\n",
    "        T_exp    : time to expiry (years)\n",
    "        r_val    : risk-free rate\n",
    "        q_val    : dividend yield\n",
    "        sigma_fn : interpolated vol function sigma(K)\n",
    "        delta_frac : step size as fraction of forward\n",
    "    \"\"\"\n",
    "    F_exp = S * np.exp((r_val - q_val) * T_exp)\n",
    "    Delta = delta_frac * F_exp\n",
    "    discount = np.exp(r_val * T_exp)\n",
    "    \n",
    "    def _c(K):\n",
    "        return bs_call_price(S, np.atleast_1d(K), T_exp, r_val, q_val, sigma_fn(np.atleast_1d(K)))\n",
    "    \n",
    "    c_up = _c(K_grid + Delta)\n",
    "    c_dn = _c(K_grid - Delta)\n",
    "    c_ctr = _c(K_grid)\n",
    "    \n",
    "    pdf = discount * (c_up + c_dn - 2.0 * c_ctr) / (Delta**2)\n",
    "    pdf = np.maximum(pdf, 0)\n",
    "    total = trapz(pdf, K_grid)\n",
    "    if total > 0:\n",
    "        pdf = pdf / total\n",
    "    return pdf\n",
    "\n",
    "# --- Compute RND for each expiry on moneyness grid ---\n",
    "m_rnd = np.linspace(0.80, 1.20, 300)\n",
    "K_rnd_grid = m_rnd * S0\n",
    "rnd_matrix = []\n",
    "\n",
    "for d in surface_data:\n",
    "    pdf_exp = breeden_litzenberger_general(\n",
    "        K_rnd_grid, S0, d['T'], r, q, d['sigma_fn']\n",
    "    )\n",
    "    # Convert from price-space density to moneyness-space: f_m = f_K * S0\n",
    "    rnd_matrix.append(pdf_exp * S0)\n",
    "\n",
    "rnd_matrix = np.array(rnd_matrix)\n",
    "\n",
    "# --- 3D RND Surface ---\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Surface(\n",
    "    x=m_rnd, y=dte_vals, z=rnd_matrix,\n",
    "    colorscale='RdBu_r', opacity=0.85,\n",
    "    colorbar=dict(title='Density'),\n",
    "    name='RND Surface'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'3D Risk-Neutral Density Surface \u2014 {TICKER}',\n",
    "    scene=dict(\n",
    "        xaxis_title='Moneyness (K/S)',\n",
    "        yaxis_title='Days to Expiry',\n",
    "        zaxis_title='Probability Density',\n",
    "        camera=dict(eye=dict(x=1.8, y=-1.8, z=1.0))\n",
    "    ),\n",
    "    template='plotly_white',\n",
    "    width=1000, height=700\n",
    ")\n",
    "fig.show()\n",
    "save_plotly_figure(fig, \"10_rnd_surface_3d\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "px94t62wngt",
   "source": "## Step 12b: Risk-Neutral CDF Surface\n\nThe **cumulative distribution function** $F(K) = P(S_T \\le K)$ at each expiry shows how cumulative probability builds across strikes. Key features:\n\n- The **median** (CDF = 0.5) traces the market's central expectation of $S_T$ across maturities\n- The **5th percentile** (CDF = 0.05) traces the market-implied tail risk threshold\n- Wider CDF spread at longer maturities reflects greater uncertainty",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "i7s68sl0pl9",
   "source": [
    "# --- Risk-Neutral CDF Surface ---\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "\n",
    "m_cdf = np.linspace(0.80, 1.20, 300)\n",
    "K_cdf = m_cdf * S0\n",
    "cdf_matrix = []\n",
    "median_moneyness = []\n",
    "p5_moneyness = []\n",
    "\n",
    "for d in surface_data:\n",
    "    pdf_exp = breeden_litzenberger_general(K_cdf, S0, d['T'], r, q, d['sigma_fn'])\n",
    "    cdf_exp = cumulative_trapezoid(pdf_exp, K_cdf, initial=0)\n",
    "    # Normalize to [0, 1]\n",
    "    if cdf_exp[-1] > 0:\n",
    "        cdf_exp = cdf_exp / cdf_exp[-1]\n",
    "    cdf_matrix.append(cdf_exp)\n",
    "\n",
    "    # Find median (CDF = 0.5) and 5th percentile (CDF = 0.05)\n",
    "    idx_50 = np.searchsorted(cdf_exp, 0.5)\n",
    "    idx_05 = np.searchsorted(cdf_exp, 0.05)\n",
    "    median_moneyness.append(m_cdf[min(idx_50, len(m_cdf) - 1)])\n",
    "    p5_moneyness.append(m_cdf[min(idx_05, len(m_cdf) - 1)])\n",
    "\n",
    "cdf_matrix = np.array(cdf_matrix)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Surface(\n",
    "    x=m_cdf, y=dte_vals, z=cdf_matrix,\n",
    "    colorscale='Viridis', opacity=0.85,\n",
    "    colorbar=dict(title='CDF')\n",
    "))\n",
    "\n",
    "# Median line (CDF = 0.5)\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=median_moneyness, y=dte_vals,\n",
    "    z=np.full(len(dte_vals), 0.5),\n",
    "    mode='lines+markers',\n",
    "    marker=dict(size=4, color='red'),\n",
    "    line=dict(color='red', width=4),\n",
    "    name='Median (CDF=0.5)'\n",
    "))\n",
    "\n",
    "# 5th percentile line (CDF = 0.05)\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=p5_moneyness, y=dte_vals,\n",
    "    z=np.full(len(dte_vals), 0.05),\n",
    "    mode='lines+markers',\n",
    "    marker=dict(size=4, color='orange'),\n",
    "    line=dict(color='orange', width=4),\n",
    "    name='5th Percentile (CDF=0.05)'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Risk-Neutral CDF Surface \u2014 {TICKER}',\n",
    "    scene=dict(\n",
    "        xaxis_title='Moneyness (K/S)',\n",
    "        yaxis_title='Days to Expiry',\n",
    "        zaxis_title='Cumulative Probability',\n",
    "        camera=dict(eye=dict(x=1.8, y=-1.8, z=1.0))\n",
    "    ),\n",
    "    template='plotly_white',\n",
    "    width=1000, height=700\n",
    ")\n",
    "fig.show()\n",
    "save_plotly_figure(fig, \"11_cdf_surface_3d\")\n",
    "\n",
    "print(\"CDF surface: monotonically increasing from 0 to 1 at each maturity slice.\")\n",
    "print(f\"Median moneyness by DTE: {dict(zip([d['dte'] for d in surface_data], np.round(median_moneyness, 4)))}\")\n",
    "print(f\"5th %-ile moneyness by DTE: {dict(zip([d['dte'] for d in surface_data], np.round(p5_moneyness, 4)))}\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8ms6uipm3dn",
   "source": "## Step 13: Term Structure of Risk-Neutral Moments\n\nHow do the moments of the risk-neutral distribution evolve with maturity? We compute\nskewness, excess kurtosis, standard deviation, and left-tail probability ($P(S_T < 0.9 S_0)$)\nfor each expiry and compare against the lognormal benchmark. This reveals whether\nthe market's departure from Black-Scholes is persistent or maturity-dependent.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "m2ug085trig",
   "source": [
    "# --- Term structure of moments ---\n",
    "K_moments = np.linspace(S0 * 0.70, S0 * 1.30, 1500)\n",
    "term_moments_mkt = []\n",
    "term_moments_ln = []\n",
    "term_dtes = []\n",
    "\n",
    "for d in surface_data:\n",
    "    # Market-implied RND\n",
    "    pdf_mkt = breeden_litzenberger_general(K_moments, S0, d['T'], r, q, d['sigma_fn'])\n",
    "    mkt_m = compute_moments(K_moments, pdf_mkt)\n",
    "    \n",
    "    # Lognormal benchmark (use ATM vol for this expiry)\n",
    "    sigma_atm_exp = float(d['sigma_fn'](np.array([S0]))[0])\n",
    "    mu_ln_exp = np.log(S0) + (r - q - 0.5 * sigma_atm_exp**2) * d['T']\n",
    "    sigma_ln_exp = sigma_atm_exp * np.sqrt(d['T'])\n",
    "    ln_pdf_exp = (1.0 / (K_moments * sigma_ln_exp * np.sqrt(2*np.pi))) * \\\n",
    "                 np.exp(-0.5 * ((np.log(K_moments) - mu_ln_exp) / sigma_ln_exp)**2)\n",
    "    ln_m = compute_moments(K_moments, ln_pdf_exp)\n",
    "    \n",
    "    # Left-tail probability: P(S_T < 0.9 * S0)\n",
    "    K_tail = S0 * 0.90\n",
    "    mask_tail = K_moments <= K_tail\n",
    "    mkt_m['left_tail_10'] = trapz(pdf_mkt[mask_tail], K_moments[mask_tail]) if mask_tail.any() else 0\n",
    "    ln_m['left_tail_10'] = norm.cdf((np.log(K_tail) - mu_ln_exp) / sigma_ln_exp)\n",
    "    \n",
    "    term_moments_mkt.append(mkt_m)\n",
    "    term_moments_ln.append(ln_m)\n",
    "    term_dtes.append(d['dte'])\n",
    "\n",
    "term_dtes = np.array(term_dtes)\n",
    "\n",
    "# --- 2x2 Term structure plot ---\n",
    "fig = make_subplots(rows=2, cols=2, subplot_titles=(\n",
    "    'Standard Deviation', 'Skewness', 'Excess Kurtosis', 'Left Tail P(decline > 10%)'\n",
    "), vertical_spacing=0.12, horizontal_spacing=0.10)\n",
    "\n",
    "metrics = [\n",
    "    ('std', 'Std Dev ($)'),\n",
    "    ('skewness', 'Skewness'),\n",
    "    ('excess_kurtosis', 'Excess Kurtosis'),\n",
    "    ('left_tail_10', 'Probability')\n",
    "]\n",
    "\n",
    "for i, (key, ylabel) in enumerate(metrics):\n",
    "    row, col = divmod(i, 2)\n",
    "    row += 1; col += 1\n",
    "    mkt_vals = [m[key] for m in term_moments_mkt]\n",
    "    ln_vals = [m[key] for m in term_moments_ln]\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=term_dtes, y=mkt_vals, mode='lines+markers',\n",
    "        name='Market' if i == 0 else None, showlegend=(i == 0),\n",
    "        line=dict(color='#EF553B', width=2), marker=dict(size=7),\n",
    "        legendgroup='mkt'\n",
    "    ), row=row, col=col)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=term_dtes, y=ln_vals, mode='lines+markers',\n",
    "        name='Lognormal' if i == 0 else None, showlegend=(i == 0),\n",
    "        line=dict(color='#636EFA', width=2, dash='dash'), marker=dict(size=7),\n",
    "        legendgroup='ln'\n",
    "    ), row=row, col=col)\n",
    "    fig.update_yaxes(title_text=ylabel, row=row, col=col)\n",
    "    fig.update_xaxes(title_text='DTE', row=row, col=col)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Term Structure of Risk-Neutral Moments \u2014 {TICKER}',\n",
    "    template='plotly_white', width=1050, height=700,\n",
    "    legend=dict(x=0.02, y=0.98)\n",
    ")\n",
    "fig.show()\n",
    "save_plotly_figure(fig, \"12_term_structure_moments\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "lzj1v0dm0wb",
   "source": "## Step 14: Mixture of Lognormals (Jackwerth 2004, Exhibit 1)\n\nA **mixture of two lognormals** is a simple parametric model for the risk-neutral density\n(Jackwerth 2004, Sec. 2.1, Exhibit 1). The call price under a 2-component mixture is:\n\n$$c_{\\text{mix}}(K) = w \\cdot \\text{BS}(K, \\sigma_1) + (1-w) \\cdot \\text{BS}(K, \\sigma_2)$$\n\nwhere $w \\in [0,1]$ is the mixing weight and $\\sigma_1, \\sigma_2$ are two volatility levels.\nThis allows the model to capture skew and fat tails that a single lognormal cannot.\n\nWe fit the three parameters $(w, \\sigma_1, \\sigma_2)$ by minimising the sum of squared \nimplied volatility errors against the market smile.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "lsqdxrryy0f",
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def mixture_call_price(K, S, T_val, r_val, q_val, w, sigma1, sigma2):\n",
    "    \"\"\"Call price under a 2-component lognormal mixture.\"\"\"\n",
    "    return w * bs_call_price(S, K, T_val, r_val, q_val, sigma1) + \\\n",
    "           (1 - w) * bs_call_price(S, K, T_val, r_val, q_val, sigma2)\n",
    "\n",
    "def mixture_implied_vol(K_arr, S, T_val, r_val, q_val, w, sigma1, sigma2):\n",
    "    \"\"\"Compute the implied vol of the mixture model at each strike.\"\"\"\n",
    "    mix_prices = mixture_call_price(K_arr, S, T_val, r_val, q_val, w, sigma1, sigma2)\n",
    "    ivs = []\n",
    "    for K_i, p_i in zip(K_arr, mix_prices):\n",
    "        iv = implied_vol_call(p_i, S, K_i, T_val, r_val, q_val)\n",
    "        ivs.append(iv if iv is not None else np.nan)\n",
    "    return np.array(ivs)\n",
    "\n",
    "# Fit to the single-expiry smile data\n",
    "K_smile = smile['strike'].values\n",
    "iv_smile = smile['iv'].values\n",
    "\n",
    "def objective(params):\n",
    "    w, s1, s2 = params\n",
    "    iv_model = mixture_implied_vol(K_smile, S0, T, r, q, w, s1, s2)\n",
    "    valid = ~np.isnan(iv_model)\n",
    "    if valid.sum() < 3:\n",
    "        return 1e6\n",
    "    return np.sum((iv_model[valid] - iv_smile[valid])**2)\n",
    "\n",
    "# Initial guess and bounds\n",
    "x0 = [0.7, sigma_atm * 0.8, sigma_atm * 1.5]\n",
    "bounds = [(0.01, 0.99), (0.01, 2.0), (0.01, 2.0)]\n",
    "\n",
    "result = minimize(objective, x0, method='L-BFGS-B', bounds=bounds)\n",
    "w_fit, sigma1_fit, sigma2_fit = result.x\n",
    "print(f\"Mixture fit: w={w_fit:.4f}, sigma1={sigma1_fit:.4f}, sigma2={sigma2_fit:.4f}\")\n",
    "print(f\"Residual SSE: {result.fun:.8f}\")\n",
    "\n",
    "# --- Compute mixture density analytically ---\n",
    "# Mixture PDF = w * lognormal(sigma1) + (1-w) * lognormal(sigma2)\n",
    "mu1 = np.log(S0) + (r - q - 0.5 * sigma1_fit**2) * T\n",
    "s1 = sigma1_fit * np.sqrt(T)\n",
    "mu2 = np.log(S0) + (r - q - 0.5 * sigma2_fit**2) * T\n",
    "s2 = sigma2_fit * np.sqrt(T)\n",
    "\n",
    "ln_pdf1 = (1.0 / (K_rnd * s1 * np.sqrt(2*np.pi))) * np.exp(-0.5*((np.log(K_rnd)-mu1)/s1)**2)\n",
    "ln_pdf2 = (1.0 / (K_rnd * s2 * np.sqrt(2*np.pi))) * np.exp(-0.5*((np.log(K_rnd)-mu2)/s2)**2)\n",
    "mixture_pdf = w_fit * ln_pdf1 + (1 - w_fit) * ln_pdf2\n",
    "\n",
    "# --- Plot: BL-extracted vs mixture vs single lognormal ---\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=K_rnd, y=rn_pdf_norm, mode='lines', name='BL-Extracted RND',\n",
    "                         line=dict(color='#EF553B', width=2.5)))\n",
    "fig.add_trace(go.Scatter(x=K_rnd, y=mixture_pdf, mode='lines', name=f'Mixture (w={w_fit:.2f})',\n",
    "                         line=dict(color='#00CC96', width=2)))\n",
    "fig.add_trace(go.Scatter(x=K_rnd, y=lognorm_pdf, mode='lines', name='Single Lognormal',\n",
    "                         line=dict(color='#636EFA', width=2, dash='dash')))\n",
    "fig.add_vline(x=F, line_dash=\"dot\", line_color=\"gray\")\n",
    "fig.update_layout(\n",
    "    title=f'Mixture of Lognormals vs BL-Extracted RND \u2014 {TICKER} ({selected_expiry})',\n",
    "    xaxis_title='Strike Price ($)', yaxis_title='Density',\n",
    "    template='plotly_white', width=950, height=500,\n",
    "    legend=dict(x=0.65, y=0.98)\n",
    ")\n",
    "fig.show()\n",
    "save_plotly_figure(fig, \"13_mixture_lognormals\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ydvl5h6b44",
   "source": "## Step 15: State Prices and Arrow-Debreu Securities (BL 1978, Theorem 1; Jackwerth 2004, Eq. 7)\n\nThe **state price density** $p(X)$ is the price today of a claim that pays \\$1 if $S_T = X$.\nIt is related to the risk-neutral density by (Jackwerth 2004, Eq. 7):\n\n$$p(X) = e^{-rT} \\cdot \\tilde{\\pi}(X)$$\n\nThe integral of state prices over all states must equal the **discount factor** (price of a \nrisk-free zero-coupon bond):\n\n$$\\int_0^\\infty p(X)\\, dX = e^{-rT}$$\n\nWe also show the **butterfly spread decomposition**: a butterfly centred at strike $X$ with\nwidth $\\Delta$ approximates an Arrow-Debreu security paying $\\Delta$ units at $S_T = X$\n(Breeden & Litzenberger 1978, Theorem 1).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "a1uyvij0fhr",
   "source": [
    "# --- State price density ---\n",
    "state_price_density = np.exp(-r * T) * rn_pdf_norm\n",
    "\n",
    "# Verify integral equals discount factor\n",
    "sp_integral = trapz(state_price_density, K_rnd)\n",
    "discount_factor = np.exp(-r * T)\n",
    "print(f\"Integral of state price density: {sp_integral:.6f}\")\n",
    "print(f\"Discount factor e^(-rT):         {discount_factor:.6f}\")\n",
    "print(f\"Error:                           {abs(sp_integral - discount_factor):.8f}\")\n",
    "\n",
    "# --- Butterfly spread decomposition ---\n",
    "# Show discrete butterfly prices at selected strikes as Arrow-Debreu approximations\n",
    "Delta_bf = 0.025 * F\n",
    "bf_strikes = np.arange(S0 * 0.85, S0 * 1.15, Delta_bf)\n",
    "bf_prices = []\n",
    "for K_bf in bf_strikes:\n",
    "    c_up = call_value(np.array([K_bf + Delta_bf]))[0]\n",
    "    c_dn = call_value(np.array([K_bf - Delta_bf]))[0]\n",
    "    c_ctr = call_value(np.array([K_bf]))[0]\n",
    "    bf_price = (c_up + c_dn - 2 * c_ctr)  # butterfly spread cost\n",
    "    bf_prices.append(bf_price)\n",
    "bf_prices = np.array(bf_prices)\n",
    "\n",
    "# Butterfly price / Delta^2 should approximate state price density\n",
    "bf_density_approx = bf_prices / (Delta_bf**2)\n",
    "\n",
    "# --- Plot ---\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\n",
    "    'State Price Density p(X)', 'Butterfly Spread Decomposition'\n",
    "), horizontal_spacing=0.10)\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=K_rnd, y=state_price_density, mode='lines',\n",
    "    name='State Price Density', line=dict(color='#AB63FA', width=2.5)\n",
    "), row=1, col=1)\n",
    "fig.add_vline(x=F, line_dash=\"dot\", line_color=\"gray\", row=1, col=1)\n",
    "fig.update_yaxes(title_text='State Price Density', row=1, col=1)\n",
    "fig.update_xaxes(title_text='Strike ($)', row=1, col=1)\n",
    "\n",
    "# Butterfly approx vs continuous\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=K_rnd, y=state_price_density, mode='lines',\n",
    "    name='Continuous (BL)', line=dict(color='#AB63FA', width=2), showlegend=True\n",
    "), row=1, col=2)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=bf_strikes, y=bf_density_approx, width=Delta_bf * 0.8,\n",
    "    name='Butterfly Approximation', marker_color='rgba(99,110,250,0.5)'\n",
    "), row=1, col=2)\n",
    "fig.update_yaxes(title_text='Density', row=1, col=2)\n",
    "fig.update_xaxes(title_text='Strike ($)', row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'State Prices & Arrow-Debreu Securities \u2014 {TICKER} ({selected_expiry})',\n",
    "    template='plotly_white', width=1100, height=450\n",
    ")\n",
    "fig.show()\n",
    "save_plotly_figure(fig, \"14_state_prices\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "iai6hx0z2l",
   "source": "## Step 16: No-Arbitrage Smile Slope Bounds (Malz 2014, Eq. 7\u20138)\n\nThe volatility smile must satisfy slope constraints to avoid arbitrage. Using the chain rule\non the call price $c(X) = v[S, X, T, \\sigma(X), r, q]$:\n\n$$\\frac{\\partial c}{\\partial X} = v_X + v_\\sigma \\cdot \\frac{d\\sigma}{dX}$$\n\n**Upper bound** (monotonicity: $\\partial c/\\partial X \\leq 0$, Malz 2014, Eq. 7):\n\n$$\\frac{d\\sigma}{dX} \\leq -\\frac{v_X}{v_\\sigma}$$\n\n**Lower bound** (bounded slope: $\\partial c/\\partial X \\geq -e^{-rT}$, Malz 2014, Eq. 8):\n\n$$\\frac{d\\sigma}{dX} \\geq -\\frac{v_X + e^{-rT}}{v_\\sigma}$$\n\nViolations of the upper bound produce negative densities; violations of the lower bound\nproduce CDF values outside $[0, 1]$.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ez4s38cvrl",
   "source": [
    "# --- No-arbitrage smile slope bounds (Malz 2014, Eq. 7-8) ---\n",
    "K_bounds = np.linspace(S0 * 0.82, S0 * 1.18, 500)\n",
    "sigma_vals = sigma_interp(K_bounds)\n",
    "\n",
    "# v_X: partial derivative of BS call w.r.t. strike (exercise-price delta)\n",
    "d2_vals = bs_d2(S0, K_bounds, T, r, q, sigma_vals)\n",
    "v_X = -np.exp(-r * T) * norm.cdf(d2_vals)\n",
    "\n",
    "# v_sigma: vega\n",
    "v_sigma = bs_vega(S0, K_bounds, T, r, q, sigma_vals)\n",
    "\n",
    "# Actual smile slope (numerical derivative of spline)\n",
    "dK = K_bounds[1] - K_bounds[0]\n",
    "sigma_slope = np.gradient(sigma_vals, dK)\n",
    "\n",
    "# Bounds\n",
    "upper_bound = -v_X / np.where(v_sigma > 1e-10, v_sigma, np.inf)\n",
    "lower_bound = -(v_X + np.exp(-r * T)) / np.where(v_sigma > 1e-10, v_sigma, np.inf)\n",
    "\n",
    "# Count violations\n",
    "upper_violations = np.sum(sigma_slope > upper_bound)\n",
    "lower_violations = np.sum(sigma_slope < lower_bound)\n",
    "print(f\"Upper bound violations: {upper_violations}/{len(K_bounds)}\")\n",
    "print(f\"Lower bound violations: {lower_violations}/{len(K_bounds)}\")\n",
    "\n",
    "# --- Plot ---\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=K_bounds, y=sigma_slope, mode='lines',\n",
    "    name='Actual Smile Slope', line=dict(color='#EF553B', width=2.5)\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=K_bounds, y=upper_bound, mode='lines',\n",
    "    name='Upper Bound (Malz Eq. 7)', line=dict(color='#636EFA', width=1.5, dash='dash')\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=K_bounds, y=lower_bound, mode='lines',\n",
    "    name='Lower Bound (Malz Eq. 8)', line=dict(color='#00CC96', width=1.5, dash='dash')\n",
    "))\n",
    "\n",
    "# Shade no-arbitrage corridor\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.concatenate([K_bounds, K_bounds[::-1]]),\n",
    "    y=np.concatenate([upper_bound, lower_bound[::-1]]),\n",
    "    fill='toself', fillcolor='rgba(99, 110, 250, 0.08)',\n",
    "    line=dict(width=0), showlegend=True, name='No-Arbitrage Corridor'\n",
    "))\n",
    "\n",
    "fig.add_hline(y=0, line_dash=\"dot\", line_color=\"gray\")\n",
    "fig.add_vline(x=S0, line_dash=\"dot\", line_color=\"gray\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'No-Arbitrage Smile Slope Bounds \u2014 {TICKER} ({selected_expiry})',\n",
    "    xaxis_title='Strike Price ($)', yaxis_title='d\u03c3/dX (per $)',\n",
    "    template='plotly_white', width=950, height=500,\n",
    "    legend=dict(x=0.60, y=0.98)\n",
    ")\n",
    "fig.show()\n",
    "save_plotly_figure(fig, \"15_no_arbitrage_bounds\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "wwl32uqkknd",
   "source": "## Step 17: Pricing Kernel Extraction (Jackwerth 2004, Eq. 12, pp. 54\u201356)\n\nThe **pricing kernel** (stochastic discount factor) $m(S_T)$ connects the risk-neutral density\n$\\tilde{\\pi}$ to the physical (real-world) density $f^P$ (Jackwerth 2004, Eq. 12):\n\n$$m(S_T) = \\frac{\\tilde{\\pi}(S_T)}{e^{rT} \\cdot f^P(S_T)}$$\n\nUnder standard risk aversion, $m(S_T)$ should be **monotonically decreasing** in $S_T$:\ninvestors value an extra dollar more in bad states (low $S_T$) than in good states.\n\nJackwerth (2004, pp. 54\u201356) documents the **pricing kernel puzzle**: empirically, the pricing\nkernel estimated from S&P 500 options is *not* monotonically decreasing \u2014 it often increases\nover some range, inconsistent with a representative agent with concave utility.\n\nWe estimate the physical density $f^P$ from 3 years of historical SPY returns using a\nGaussian kernel density estimator.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "3yai6pn9c0i",
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# --- Fetch 3 years of historical SPY data ---\n",
    "hist_data = spy.history(period=\"3y\")\n",
    "hist_close = hist_data['Close'].values\n",
    "\n",
    "# Compute T-day rolling returns (matching option expiry horizon)\n",
    "trading_days = max(int(actual_dte * 252 / 365), 1)\n",
    "hist_returns = hist_close[trading_days:] / hist_close[:-trading_days]  # S_{t+T} / S_t\n",
    "\n",
    "# Map to future price levels: S_T = S0 * return_ratio\n",
    "hist_S_T = S0 * hist_returns\n",
    "\n",
    "print(f\"Historical return horizon: {trading_days} trading days (~{actual_dte} calendar days)\")\n",
    "print(f\"Number of overlapping return observations: {len(hist_returns)}\")\n",
    "print(f\"Historical return range: [{hist_returns.min():.4f}, {hist_returns.max():.4f}]\")\n",
    "\n",
    "# --- Estimate physical density via Gaussian KDE ---\n",
    "kde = gaussian_kde(hist_S_T, bw_method='silverman')\n",
    "physical_pdf = kde(K_rnd)\n",
    "\n",
    "# Ensure physical density is positive (for division)\n",
    "physical_pdf = np.maximum(physical_pdf, 1e-12)\n",
    "\n",
    "# --- Compute pricing kernel ---\n",
    "# m(S_T) = RND(S_T) / (e^{rT} * physical_density(S_T))\n",
    "pricing_kernel = rn_pdf_norm / (np.exp(r * T) * physical_pdf)\n",
    "\n",
    "# Focus on region with sufficient data support (moneyness 0.85-1.15)\n",
    "pk_mask = (K_rnd >= S0 * 0.85) & (K_rnd <= S0 * 1.15)\n",
    "\n",
    "# Check monotonicity\n",
    "pk_trimmed = pricing_kernel[pk_mask]\n",
    "K_trimmed = K_rnd[pk_mask]\n",
    "diffs = np.diff(pk_trimmed)\n",
    "n_increasing = np.sum(diffs > 0)\n",
    "print(f\"\\nPricing kernel monotonicity check (0.85-1.15 moneyness):\")\n",
    "print(f\"  Increasing segments: {n_increasing}/{len(diffs)} ({n_increasing/len(diffs)*100:.1f}%)\")\n",
    "print(f\"  {'NOT monotonically decreasing (pricing kernel puzzle!)' if n_increasing > len(diffs)*0.1 else 'Approximately monotonically decreasing'}\")\n",
    "\n",
    "# --- 2-panel plot ---\n",
    "fig = make_subplots(rows=2, cols=1, subplot_titles=(\n",
    "    'Risk-Neutral vs Physical Density',\n",
    "    'Pricing Kernel m(S_T)'\n",
    "), vertical_spacing=0.12, row_heights=[0.45, 0.55])\n",
    "\n",
    "# Top: densities\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=K_rnd, y=rn_pdf_norm, mode='lines', name='Risk-Neutral (Q)',\n",
    "    line=dict(color='#EF553B', width=2.5)\n",
    "), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=K_rnd, y=physical_pdf, mode='lines', name='Physical (P, KDE)',\n",
    "    line=dict(color='#636EFA', width=2)\n",
    "), row=1, col=1)\n",
    "fig.add_vline(x=F, line_dash=\"dot\", line_color=\"gray\", row=1, col=1)\n",
    "\n",
    "# Bottom: pricing kernel\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=K_rnd[pk_mask], y=pricing_kernel[pk_mask], mode='lines',\n",
    "    name='Pricing Kernel', line=dict(color='#AB63FA', width=2.5)\n",
    "), row=2, col=1)\n",
    "fig.add_hline(y=1.0, line_dash=\"dash\", line_color=\"gray\", row=2, col=1)\n",
    "fig.add_vline(x=S0, line_dash=\"dot\", line_color=\"gray\", row=2, col=1)\n",
    "\n",
    "# Add moneyness axis\n",
    "moneyness_ticks = K_rnd[pk_mask] / S0\n",
    "\n",
    "fig.update_xaxes(title_text='Strike Price ($)', row=1, col=1)\n",
    "fig.update_xaxes(title_text='Strike Price ($)', row=2, col=1)\n",
    "fig.update_yaxes(title_text='Density', row=1, col=1)\n",
    "fig.update_yaxes(title_text='m(S_T)', row=2, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Pricing Kernel Extraction \u2014 {TICKER} ({selected_expiry}, Jackwerth 2004)',\n",
    "    template='plotly_white', width=950, height=750,\n",
    "    legend=dict(x=0.65, y=0.98)\n",
    ")\n",
    "fig.show()\n",
    "save_plotly_figure(fig, \"16_pricing_kernel\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3f19gagibuh",
   "source": "## Step 17b: 3D Pricing Kernel Surface\n\nThe **pricing kernel** $m(S_T) = \\tilde{\\pi}(S_T) \\;/\\; \\bigl(e^{rT}\\, p(S_T)\\bigr)$ connects risk-neutral to physical probabilities (Jackwerth 2004, Eq. 12). Plotting $m$ across moneyness $\\times$ maturity reveals:\n\n- A **generally decreasing** kernel (risk aversion: bad states are expensive)\n- Potential **non-monotonicity** at intermediate returns \u2014 the *pricing kernel puzzle*\n- How the puzzle's severity varies with horizon\n\n**Caveat:** The physical density is estimated via Gaussian KDE on historical returns, which is noisy in the tails. The surface is restricted to moneyness 0.88\u20131.12 for stability.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "1c8cmirbakr",
   "source": [
    "# --- 3D Pricing Kernel Surface ---\n",
    "from scipy.stats import gaussian_kde as gkde\n",
    "\n",
    "def estimate_physical_density(hist_close, S0, K_grid, horizon_days):\n",
    "    \"\"\"Estimate physical density at strike grid via KDE on historical returns.\"\"\"\n",
    "    trading_days_h = max(int(horizon_days * 252 / 365), 1)\n",
    "    if trading_days_h >= len(hist_close):\n",
    "        trading_days_h = len(hist_close) - 1\n",
    "    returns = hist_close[trading_days_h:] / hist_close[:-trading_days_h]\n",
    "    S_T_hist = S0 * returns\n",
    "    kde_est = gkde(S_T_hist, bw_method='silverman')\n",
    "    return np.maximum(kde_est(K_grid), 1e-12)\n",
    "\n",
    "m_pk = np.linspace(0.88, 1.12, 200)\n",
    "K_pk = m_pk * S0\n",
    "pk_matrix = []\n",
    "\n",
    "for d in surface_data:\n",
    "    # Risk-neutral density\n",
    "    rnd_exp = breeden_litzenberger_general(K_pk, S0, d['T'], r, q, d['sigma_fn'])\n",
    "    # Physical density\n",
    "    phys_exp = estimate_physical_density(hist_close, S0, K_pk, d['dte'])\n",
    "    # Pricing kernel: m = RND / (e^{rT} * physical)\n",
    "    pk_exp = rnd_exp / (np.exp(r * d['T']) * phys_exp)\n",
    "    pk_matrix.append(pk_exp)\n",
    "\n",
    "pk_matrix = np.array(pk_matrix)\n",
    "\n",
    "# Clip extreme values for visualization stability (KDE noise causes spikes at short maturities)\n",
    "pk_cap = np.percentile(pk_matrix, 95)\n",
    "pk_clip = np.clip(pk_matrix, 0, pk_cap)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Pricing kernel surface\n",
    "fig.add_trace(go.Surface(\n",
    "    x=m_pk, y=dte_vals, z=pk_clip,\n",
    "    colorscale='Plasma', opacity=0.85,\n",
    "    colorbar=dict(title='m(S_T)')\n",
    "))\n",
    "\n",
    "# Semi-transparent m=1 reference plane\n",
    "m1_plane = np.ones_like(pk_clip)\n",
    "fig.add_trace(go.Surface(\n",
    "    x=m_pk, y=dte_vals, z=m1_plane,\n",
    "    colorscale=[[0, 'rgba(128,128,128,0.3)'], [1, 'rgba(128,128,128,0.3)']],\n",
    "    opacity=0.3, showscale=False, name='m=1 reference'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'3D Pricing Kernel Surface \u2014 {TICKER} (Jackwerth 2004)',\n",
    "    scene=dict(\n",
    "        xaxis_title='Moneyness (K/S)',\n",
    "        yaxis_title='Days to Expiry',\n",
    "        zaxis_title='Pricing Kernel m(S_T)',\n",
    "        camera=dict(eye=dict(x=1.8, y=-1.8, z=1.0))\n",
    "    ),\n",
    "    template='plotly_white',\n",
    "    width=1000, height=700\n",
    ")\n",
    "fig.show()\n",
    "save_plotly_figure(fig, \"17_pricing_kernel_surface_3d\")\n",
    "\n",
    "print(f\"Pricing kernel surface clipped at p95={pk_cap:.2f} (KDE noise causes spikes at short maturities).\")\n",
    "print(\"m(S_T) should generally decrease in S_T (risk aversion).\")\n",
    "print(\"Non-monotonicity = pricing kernel puzzle (Jackwerth 2000).\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "tl63x1z4oj",
   "source": "## Step 18: P&L Landscape \u2014 ATM Straddle\n\nAn **ATM straddle** (long call + long put at the same strike) profits from large moves in either direction. Its P&L depends on two dimensions:\n\n- **Underlying price** (x-axis): V-shaped payoff \u2014 profits grow as $|S - K|$ increases\n- **Time remaining** (y-axis): Time decay erodes option value \u2014 the straddle loses value if the underlying doesn't move\n\nThe surface shows how the P&L evolves from entry (full $T$ remaining) to expiry (near zero), using market-implied IV for realistic pricing.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "1by4j22q6v3",
   "source": [
    "# --- P&L Landscape: ATM Straddle ---\n",
    "# Use the nearest-expiry smile for ATM vol\n",
    "sigma_atm_straddle = float(sigma_interp(np.array([S0]))[0])\n",
    "\n",
    "# Entry cost: ATM call + ATM put at inception\n",
    "entry_call = bs_call_price(S0, S0, T, r, q, sigma_atm_straddle)\n",
    "entry_put = bs_put_price(S0, S0, T, r, q, sigma_atm_straddle)\n",
    "entry_cost = entry_call + entry_put\n",
    "\n",
    "# Grid: underlying price \u00d7 time remaining\n",
    "S_grid = np.linspace(S0 * 0.85, S0 * 1.15, 200)\n",
    "t_remaining = np.linspace(T, 1 / 365.0, 100)  # from full T down to ~1 day\n",
    "days_remaining = t_remaining * 365\n",
    "\n",
    "pnl_matrix = np.zeros((len(t_remaining), len(S_grid)))\n",
    "\n",
    "for i, t_rem in enumerate(t_remaining):\n",
    "    # Price straddle at each (S, t) using ATM vol (constant vol approximation)\n",
    "    call_val = bs_call_price(S_grid, S0, t_rem, r, q, sigma_atm_straddle)\n",
    "    put_val = bs_put_price(S_grid, S0, t_rem, r, q, sigma_atm_straddle)\n",
    "    pnl_matrix[i, :] = (call_val + put_val) - entry_cost\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Surface(\n",
    "    x=S_grid, y=days_remaining, z=pnl_matrix,\n",
    "    colorscale='RdYlGn', opacity=0.85, cmid=0,\n",
    "    colorbar=dict(title='P&L ($)')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'ATM Straddle P&L Landscape \u2014 {TICKER} (K=${S0:.0f}, IV={sigma_atm_straddle*100:.1f}%)',\n",
    "    scene=dict(\n",
    "        xaxis_title='Underlying Price ($)',\n",
    "        yaxis_title='Days Remaining',\n",
    "        zaxis_title='P&L ($)',\n",
    "        camera=dict(eye=dict(x=1.8, y=-1.8, z=1.0))\n",
    "    ),\n",
    "    template='plotly_white',\n",
    "    width=1000, height=700\n",
    ")\n",
    "fig.show()\n",
    "save_plotly_figure(fig, \"18_straddle_pnl_landscape\")\n",
    "\n",
    "print(f\"ATM straddle entry cost: ${entry_cost:.2f}\")\n",
    "print(f\"Breakeven at expiry: ${S0 - entry_cost:.2f} and ${S0 + entry_cost:.2f}\")\n",
    "print(f\"Breakeven moneyness: {(S0 - entry_cost)/S0:.4f} and {(S0 + entry_cost)/S0:.4f}\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "rbk9gboocsl",
   "source": "## References\n\n1. **Breeden, D.T. and Litzenberger, R.H.** (1978). \"Prices of State-Contingent Claims Implicit in Option Prices.\" *Journal of Business*, 51(4), 621\u2013651.\n   - **Theorem 1**: Call options on aggregate consumption span all Arrow-Debreu securities.\n   - **Eq. 2**: $\\tilde{\\pi}(X) = e^{rT} \\partial^2 c / \\partial X^2$ \u2014 the core BL result (Steps 5, 12, 15).\n   - **Eq. 5**: Explicit derivation that BL applied to BS recovers the lognormal density (Step 6).\n\n2. **Malz, A.M.** (2014). \"A Simple and Reliable Way to Compute Option-Based Risk-Neutral Distributions.\" *Fed. Reserve Bank of New York Staff Reports*, No. 677.\n   - **Eq. 2\u20133**: CDF and PDF via finite differences (Step 5).\n   - **Eq. 4**: Call valuation function from interpolated smile (Step 4).\n   - **Eq. 5\u20136**: Clamped cubic spline boundary conditions (Step 4).\n   - **Eq. 7\u20138**: No-arbitrage upper/lower bounds on smile slope (Step 16).\n   - **Sec. 2.4**: Smoothing parameter $\\Delta$ selection (Step 8).\n   - **Sec. 2.5**: Diagnostic checks \u2014 CDF bounds, mean check, exercise-price deltas (Step 10).\n\n3. **Jackwerth, J.C.** (2004). \"Option-Implied Risk-Neutral Distributions and Risk Aversion.\" *Research Foundation of CFA Institute*.\n   - **Exhibit 1**: Mixture of lognormals as parametric RND model (Step 14).\n   - **Eq. 7**: State price density $p(X) = e^{-rT} \\tilde{\\pi}(X)$ (Step 15).\n   - **Eq. 12**: Pricing kernel $m(S_T) = \\tilde{\\pi}(S_T) / [e^{rT} f^P(S_T)]$ (Step 17).\n   - **pp. 54\u201356**: The pricing kernel puzzle \u2014 non-monotonic pricing kernels (Step 17).",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "r9vaf81r34h",
   "source": "## Summary: Static Publication-Quality Figure\n\nA single matplotlib figure summarising the full pipeline for export/presentation.\nExpanded to 3x2 to include the pricing kernel and mixture model comparison.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "p37i07fc03",
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(14, 15))\n",
    "fig.suptitle(f'Breeden-Litzenberger Risk-Neutral Distribution \u2014 {TICKER} ({selected_expiry}, {actual_dte} DTE)',\n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "# (1) Volatility Smile\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(smile['strike'], smile['iv'] * 100, s=15, color='red', alpha=0.7, label='Market IV', zorder=5)\n",
    "ax.plot(K_fine, sigma_fine * 100, 'b-', linewidth=1.5, label='Spline Fit')\n",
    "ax.axvline(S0, color='gray', linestyle='--', alpha=0.5, label='Spot')\n",
    "ax.set_xlabel('Strike ($)')\n",
    "ax.set_ylabel('Implied Volatility (%)')\n",
    "ax.set_title('Volatility Smile')\n",
    "ax.legend(fontsize=8)\n",
    "ax.set_xlim(S0 * 0.80, S0 * 1.20)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# (2) Call Valuation Function\n",
    "ax = axes[0, 1]\n",
    "ax.plot(K_fine, C_fine, 'b-', linewidth=1.5, label='c(K) from spline')\n",
    "ax.scatter(calls['strike'], calls['mid'], s=12, color='red', alpha=0.5, label='Market calls', zorder=5)\n",
    "ax.axvline(S0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_xlabel('Strike ($)')\n",
    "ax.set_ylabel('Call Price ($)')\n",
    "ax.set_title('Call Valuation Function')\n",
    "ax.legend(fontsize=8)\n",
    "ax.set_xlim(S0 * 0.80, S0 * 1.20)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# (3) Risk-Neutral PDF\n",
    "ax = axes[1, 0]\n",
    "ax.plot(K_rnd, rn_pdf_norm, 'r-', linewidth=2, label='Market-Implied RND')\n",
    "ax.plot(K_rnd, lognorm_pdf, 'b--', linewidth=1.5, label='Lognormal (BS)')\n",
    "ax.fill_between(K_rnd, rn_pdf_norm, alpha=0.15, color='red')\n",
    "ax.axvline(F, color='gray', linestyle=':', alpha=0.5, label=f'Forward ${F:.0f}')\n",
    "ax.set_xlabel('Strike ($)')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Risk-Neutral Probability Density')\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# (4) Risk-Neutral CDF\n",
    "ax = axes[1, 1]\n",
    "ax.plot(K_rnd, rn_cdf, 'r-', linewidth=2, label='Market-Implied CDF')\n",
    "ax.plot(K_rnd, lognorm_cdf, 'b--', linewidth=1.5, label='Lognormal CDF')\n",
    "ax.axvline(F, color='gray', linestyle=':', alpha=0.5)\n",
    "ax.axhline(0.5, color='lightgray', linestyle=':', alpha=0.5)\n",
    "ax.set_xlabel('Strike ($)')\n",
    "ax.set_ylabel('Cumulative Probability')\n",
    "ax.set_title('Risk-Neutral CDF')\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# (5) Pricing Kernel\n",
    "ax = axes[2, 0]\n",
    "ax.plot(K_rnd[pk_mask], pricing_kernel[pk_mask], '-', color='purple', linewidth=2, label='Pricing Kernel')\n",
    "ax.axhline(1.0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.axvline(S0, color='gray', linestyle=':', alpha=0.5, label='Spot')\n",
    "ax.set_xlabel('Strike ($)')\n",
    "ax.set_ylabel('m(S_T)')\n",
    "ax.set_title('Pricing Kernel (Jackwerth 2004)')\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# (6) Mixture vs BL-Extracted\n",
    "ax = axes[2, 1]\n",
    "ax.plot(K_rnd, rn_pdf_norm, 'r-', linewidth=2, label='BL-Extracted')\n",
    "ax.plot(K_rnd, mixture_pdf, '-', color='green', linewidth=1.5, label=f'Mixture (w={w_fit:.2f})')\n",
    "ax.plot(K_rnd, lognorm_pdf, 'b--', linewidth=1.5, label='Single Lognormal')\n",
    "ax.axvline(F, color='gray', linestyle=':', alpha=0.5)\n",
    "ax.set_xlabel('Strike ($)')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Mixture of Lognormals Comparison')\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/notes/bl_summary.png', dpi=150, bbox_inches='tight')\n",
    "plt.savefig(os.path.join(FIGURES_DIR, 'summary_publication.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Figure saved to docs/notes/bl_summary.png\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}